kerma test (Full Logging)
--------------------

- gillian stopped?

2015-07-11 09:21:07,306 DEBUG [http-nio-8080-exec-9] [AnonymousAuthenticator] postHandle() 
2015-07-11 09:21:07,306 DEBUG [http-nio-8080-exec-9] [HttpHeaderAuthenticator] postHandle() 
2015-07-11 09:21:07,306 DEBUG [http-nio-8080-exec-9] [OperationInterceptor] postHandle() 
2015-07-11 09:21:07,306 DEBUG [http-nio-8080-exec-9] [OperationInterceptor] Operation [6271864][http://peter:8080/firethorn/adql/table/6394189/datatable] 
2015-07-11 09:21:07,306 DEBUG [http-nio-8080-exec-9] [OperationInterceptor] Handler   [org.springframework.web.method.HandlerMethod] 
2015-07-11 09:21:07,306 DEBUG [http-nio-8080-exec-9] [AnonymousAuthenticator] afterCompletion() 
2015-07-11 09:21:07,306 DEBUG [http-nio-8080-exec-9] [HttpHeaderAuthenticator] afterCompletion() 
2015-07-11 09:21:07,306 DEBUG [http-nio-8080-exec-9] [OperationInterceptor] afterCompletion() 
2015-07-11 09:21:07,306 DEBUG [http-nio-8080-exec-9] [OperationInterceptor] Operation [6271864][http://peter:8080/firethorn/adql/table/6394189/datatable] 
2015-07-11 09:21:07,306 DEBUG [http-nio-8080-exec-9] [OperationInterceptor] Handler   [org.springframework.web.method.HandlerMethod] 
12-Jul-2015 15:26:45.549 INFO [main] org.apache.catalina.startup.VersionLoggerListener.log Server version: Apache Tomcat/8.0.14
12-Jul-2015 15:26:45.554 INFO [main] org.apache.catalina.startup.VersionLoggerListener.log Server built:   Sep 24 2014 09:01:51
12-Jul-2015 15:26:45.554 INFO [main] org.apache.catalina.startup.VersionLoggerListener.log Server number:  8.0.14.0
12-Jul-2015 15:26:45.554 INFO [main] org.apache.catalina.startup.VersionLoggerListener.log OS Name:        Linux
12-Jul-2015 15:26:45.554 INFO [main] org.apache.catalina.startup.VersionLoggerListener.log OS Version:     3.17.4-301.fc21.x86_64
12-Jul-2015 15:26:45.554 INFO [main] org.apache.catalina.startup.VersionLoggerListener.log Architecture:   amd64



- pyrothorn

2015-07-12 07:20:58,198 - root - INFO - 
2015-07-12 07:20:58,285 - root - INFO - Total queries: 2740
2015-07-12 07:20:58,285 - root - INFO - Total unique queries: 2740
2015-07-12 07:20:58,285 - root - INFO - Total failed: 1867
2015-07-12 07:20:58,285 - root - INFO - Coverage percentage: 100.0%
2015-07-12 07:20:58,285 - root - INFO - Success percentage: 31.86%
F
======================================================================
FAIL: test_sql_logged_queries (__main__.test_firethorn)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "testing/test_firethorn_logged_sql.py", line 288, in test_sql_logged_queries
    self.assertEqual(self.total_failed , 0, "Total queries failed: " + str(self.total_failed) + " (out of " + str(len(logged_queries)) +  ")" )
AssertionError: Total queries failed: 1867 (out of 2740)

----------------------------------------------------------------------
Ran 1 test in 140699.798s

FAILED (failures=1)



(probably because of gillian crash, we get some errors of No route to host)
2015-07-12 07:20:58,195 - root - ERROR - <urlopen error [Errno 113] No route to host>
Traceback (most recent call last):
  File "/home/pyrothorn/src/pyrothorn/queryEngine.py", line 86, in run_query
    f = urllib2.urlopen(request)
  File "/usr/lib/python2.7/urllib2.py", line 127, in urlopen
    return _opener.open(url, data, timeout)
  File "/usr/lib/python2.7/urllib2.py", line 404, in open
    response = self._open(req, data)
  File "/usr/lib/python2.7/urllib2.py", line 422, in _open
    '_open', req)
  File "/usr/lib/python2.7/urllib2.py", line 382, in _call_chain
    result = func(*args)
  File "/usr/lib/python2.7/urllib2.py", line 1214, in http_open
    return self.do_open(httplib.HTTPConnection, req)
  File "/usr/lib/python2.7/urllib2.py", line 1184, in do_open
    raise URLError(err)
URLError: <urlopen error [Errno 113] No route to host>


- ogsadai log (grep 'Exception')
 
2015-07-11 09:20:32,966 ERROR extension.ServiceAddressesActivityInitialiser [pool-1-thread-747,errorExceptionAndChildren:401] #1436620832966:21340# java.net.MalformedURLException: no protocol: ${ogsadai.endpoint}



[root@kerma ~]# df -h
Filesystem      Size  Used Avail Use% Mounted on
/dev/vda3        15G   10G  4.0G  72% /
devtmpfs        992M     0  992M   0% /dev
tmpfs          1001M     0 1001M   0% /dev/shm
tmpfs          1001M  684K 1001M   1% /run
tmpfs          1001M     0 1001M   0% /sys/fs/cgroup
tmpfs          1001M   16K 1001M   1% /tmp
/dev/vda1       488M   87M  366M  20% /boot
tmpfs           201M     0  201M   0% /run/user/0





-----------------------------------------------------------------------------------------------




hebenu (ERROR logging only)
---------------------------


- pyrothorn 


2015-07-12 17:48:23,359 - root - INFO - 
2015-07-12 17:48:23,359 - root - INFO - 
2015-07-12 17:48:23,493 - root - INFO - Total queries: 2740
2015-07-12 17:48:23,493 - root - INFO - Total unique queries: 2740
2015-07-12 17:48:23,493 - root - INFO - Total failed: 1072
2015-07-12 17:48:23,493 - root - INFO - Coverage percentage: 100.0%
2015-07-12 17:48:23,494 - root - INFO - Success percentage: 60.88%
F
======================================================================
FAIL: test_sql_logged_queries (__main__.test_firethorn)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "testing/test_firethorn_logged_sql.py", line 288, in test_sql_logged_queries
    self.assertEqual(self.total_failed , 0, "Total queries failed: " + str(self.total_failed) + " (out of " + str(len(logged_queries)) +  ")" )
AssertionError: Total queries failed: 1072 (out of 2740)

----------------------------------------------------------------------
Ran 1 test in 178309.331



- docker logs --follow --tail 1000 gillian

cationContext: startup date [Fri Jul 10 10:23:43 EDT 2015]; root of context hierarchy 
2015-07-10 10:23:54,334 INFO  [localhost-startStop-1] [RequestMappingHandlerAdapter] Looking for @ControllerAdvice: Root WebApplicationContext: startup date [Fri Jul 10 10:23:43 EDT 2015]; root of context hierarchy 
2015-07-10 10:23:54,401 INFO  [localhost-startStop-1] [ContextLoader] Root WebApplicationContext: initialization completed in 10733 ms 
10-Jul-2015 10:23:54.433 INFO [localhost-startStop-1] org.apache.catalina.startup.HostConfig.deployDirectory Deployment of web application directory /var/local/tomcat/webapps/firethorn has finished in 19,563 ms
10-Jul-2015 10:23:54.444 INFO [main] org.apache.coyote.AbstractProtocol.start Starting ProtocolHandler ["http-nio-8080"]
10-Jul-2015 10:23:54.453 INFO [main] org.apache.coyote.AbstractProtocol.start Starting ProtocolHandler ["ajp-nio-8009"]
10-Jul-2015 10:23:54.455 INFO [main] org.apache.catalina.startup.Catalina.start Server startup in 19685 ms
2015-07-10 10:24:57,521 INFO  [http-nio-8080-exec-1] [DispatcherServlet] FrameworkServlet 'spring-servlet': initialization started 
2015-07-10 10:24:57,531 INFO  [http-nio-8080-exec-1] [XmlWebApplicationContext] Refreshing WebApplicationContext for namespace 'spring-servlet-servlet': startup date [Fri Jul 10 10:24:57 EDT 2015]; parent: Root WebApplicationContext 
2015-07-10 10:24:57,533 INFO  [http-nio-8080-exec-1] [XmlBeanDefinitionReader] Loading XML bean definitions from ServletContext resource [/WEB-INF/spring/spring-servlet.xml] 
2015-07-10 10:24:57,633 INFO  [http-nio-8080-exec-1] [SimpleUrlHandlerMapping] Mapped URL path [/static/**] onto handler 'org.springframework.web.servlet.resource.ResourceHttpRequestHandler#0' 
2015-07-10 10:24:57,685 INFO  [http-nio-8080-exec-1] [DispatcherServlet] FrameworkServlet 'spring-servlet': initialization completed in 161 ms 


- docker logs --follow --tail 10000 jarmila (grep 'Exception')

2015-07-12 13:48:14,416 ERROR extension.ServiceAddressesActivityInitialiser [pool-1-thread-2453,errorExceptionAndChildren:401] #1436723294416:35953# java.net.MalformedURLException: no protocol: ${ogsadai.endpoint}


2015-07-12 13:33:58,951 DEBUG sql.SQLQueryActivity [pool-1-thread-2436,processIteration:285] Exception trying to close JDBC statement [The server returned an unspecified error.]


2015-07-11 08:58:58,819 ERROR drer.SimpleEventfulRequest [pool-2-thread-200,logStackTraceError:567] uk.org.ogsadai.exception.RequestUserException: A user problem has occurred during request processing.
	at uk.org.ogsadai.activity.concurrency.ActivityPipelineProcessingTask.createActivities(ActivityPipelineProcessingTask.java:136)
	at uk.org.ogsadai.activity.concurrency.ActivityPipelineProcessingTask.call(ActivityPipelineProcessingTask.java:103)
	at uk.org.ogsadai.activity.concurrency.ActivityPipelineProcessingTask.call(ActivityPipelineProcessingTask.java:53)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: uk.org.ogsadai.activity.ActivityUserException: A user problem has occured during activity processing.
	at uk.org.ogsadai.activity.SimpleActivityFactory.createActivity(SimpleActivityFactory.java:128)
	at uk.org.ogsadai.activity.SimpleActivityFactory.createActivities(SimpleActivityFactory.java:87)
	at uk.org.ogsadai.activity.extension.InitialisingActivityFactory.createActivities(InitialisingActivityFactory.java:66)
	at uk.org.ogsadai.activity.event.EventfulActivityFactory.createActivities(EventfulActivityFactory.java:67)
	at uk.org.ogsadai.activity.concurrency.ActivityPipelineProcessingTask.createActivities(ActivityPipelineProcessingTask.java:127)
	... 6 more
Caused by: uk.org.ogsadai.resource.ResourceUnknownException: The resource ogsadai-c3926875-4cc0-4a4f-b29e-d21fe6f65855 is unknown.
	at uk.org.ogsadai.persistence.file.resource.SimpleFileResourceStateDAO.getResourceState(SimpleFileResourceStateDAO.java:495)
	at uk.org.ogsadai.persistence.file.resource.SimpleFileResourceStateDAO.getResourceState(SimpleFileResourceStateDAO.java:597)
	at uk.org.ogsadai.resource.SimpleResourceManager.getResource(SimpleResourceManager.java:159)
	at uk.org.ogsadai.resource.SimpleResourceManager.getPublicResource(SimpleResourceManager.java:189)
	at uk.org.ogsadai.activity.SimpleActivityFactory.createActivity(SimpleActivityFactory.java:122)
	... 10 more






[root@hebenu ~]# df -h
Filesystem      Size  Used Avail Use% Mounted on
/dev/vda3        15G   11G  3.8G  74% /
devtmpfs        992M     0  992M   0% /dev
tmpfs          1001M     0 1001M   0% /dev/shm
tmpfs          1001M  652K 1001M   1% /run
tmpfs          1001M     0 1001M   0% /sys/fs/cgroup
tmpfs          1001M   32K 1001M   1% /tmp
/dev/vda1       488M   87M  366M  20% /boot
tmpfs           201M     0  201M   0% /run/user/0



[root@hebenu ~]# docker start pyrothorn
Error response from daemon: Cannot start container pyrothorn: iptables failed: iptables --wait -t filter -A DOCKER -i docker0 -o docker0 -p tcp -s 172.17.0.25 -d 172.17.0.18 --dport 8080 -j ACCEPT:  (fork/exec /usr/sbin/iptables: cannot allocate memory)
FATA[0000] Error: failed to start one or more containers


[root@hebenu ~]# free -m
              total        used        free      shared  buff/cache   available
Mem:           2001        1636          84           0         280         192
Swap:           511         402         109

[root@hebenu ~]# docker stats gillian jarmila pyrothorn patricia elayne maria mikaela
CONTAINER           CPU %               MEM USAGE/LIMIT       MEM %               NET I/O
elayne              0.00%               3.73 MiB/1.955 GiB    0.19%               17.37 GiB/17.36 GiB
gillian             0.05%               429.6 MiB/1.955 GiB   21.46%              1.488 GiB/980 MiB
jarmila             0.07%               418.5 MiB/1.955 GiB   20.91%              353.9 MiB/160.9 MiB
maria               0.00%               952 KiB/1.955 GiB     0.05%               1.827 MiB/1.769 MiB
mikaela             0.08%               209 MiB/1.955 GiB     10.44%              6.379 MiB/3.181 MiB
patricia            0.00%               5.246 MiB/1.955 GiB   0.26%               2.005 GiB/2.012 GiB
pyrothorn           0.00%               0 B/0 B               0.00%               0 B/0 B




# http://askubuntu.com/questions/253466/why-am-i-frequently-getting-this-cannot-allocate-memory-error

# Some process is leaking memory. To get an idea of which process this might be, run
# ps --sort -rss -eo rss,pid,command | head


[root@hebenu ~]# ps --sort -rss -eo rss,pid,command | head
  RSS   PID COMMAND
436136 19649 /usr/bin/java -Djava.util.logging.config.file=/var/local/tomcat/conf/logging.properties -Djava.util.logging.manager=org.apache.juli.ClassLoaderLogManager -Djava.endorsed.dirs=/var/local/tomcat/endorsed -classpath /var/local/tomcat/bin/bootstrap.jar:/var/local/tomcat/bin/tomcat-juli.jar -Dcatalina.base=/var/local/tomcat -Dcatalina.home=/var/local/tomcat -Djava.io.tmpdir=/var/local/tomcat/temp org.apache.catalina.startup.Bootstrap start
401332 19531 /usr/bin/java -Djava.util.logging.config.file=/var/local/tomcat/conf/logging.properties -Djava.util.logging.manager=org.apache.juli.ClassLoaderLogManager -Djava.endorsed.dirs=/var/local/tomcat/endorsed -classpath /var/local/tomcat/bin/bootstrap.jar:/var/local/tomcat/bin/tomcat-juli.jar -Dcatalina.base=/var/local/tomcat -Dcatalina.home=/var/local/tomcat -Djava.io.tmpdir=/var/local/tomcat/temp org.apache.catalina.startup.Bootstrap start
198992 19881 mysqld --datadir=/var/lib/mysql --user=mysql
198604 16599 /usr/bin/docker -d --selinux-enabled
14764   323 /usr/lib/systemd/systemd-journald
 8704 15432 sshd: root@pts/0
 7700     1 /usr/lib/systemd/systemd --switched-root --system --deserialize 20
 5832   426 /usr/bin/python -Es /usr/sbin/firewalld --nofork --nopid
 5540 15439 -bash




https://github.com/docker/docker/issues/2495

ubuntu@ip-10-245-18-178:~$ cat /proc/sys/vm/overcommit_memory
0
ubuntu@ip-10-245-18-178:~$ cat /proc/sys/vm/overcommit_ratio
50

@jpetazzo
jpetazzo commented on 1 Nov 2013

Okay, that's the reason why.
Even though the R process isn't using that memory, it has kind of "reserved" it, and the system makes the following reasoning: "hey, if I start new processes, and suddenly the R process starts actually using the memory, I'll have to throw someone out!". It's exactly like surbooking.

This is explained in kernel docs (look for the documentation related to the overcommit_memory parameter).

You can address the issue by setting overcommit_memory to 1, or increating overcommit_ratio; but then, the kernel might start killing processes.

You can also allocate swap space; in that case, processes won't be killed, but if the memory usage grows too much, the system might become unresponsive.

Btw, this is not specific to Docker; it's the case on any system with processes allocating (but not using) large amounts of memory (compared to the available physical memory+swap space).


(Set overcommit_memory to 1 and pyrothorn started fine)

