#
# <meta:header>
#   <meta:licence>
#     Copyright (c) 2018, ROE (http://www.roe.ac.uk/)
#
#     This information is free software: you can redistribute it and/or modify
#     it under the terms of the GNU General Public License as published by
#     the Free Software Foundation, either version 3 of the License, or
#     (at your option) any later version.
#
#     This information is distributed in the hope that it will be useful,
#     but WITHOUT ANY WARRANTY; without even the implied warranty of
#     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#     GNU General Public License for more details.
#
#     You should have received a copy of the GNU General Public License
#     along with this program.  If not, see <http://www.gnu.org/licenses/>.
#   </meta:licence>
# </meta:header>
#
#

# -----------------------------------------------------
# Create our chain properties.
#[user@builder]

    cat > "${FIRETHORN_HOME:?}/chain.properties" << EOF

        buildtag=${buildtag:?}

        metadata=$(pwgen 20 1)
        metauser=$(pwgen 20 1)
        metapass=$(pwgen 20 1)

        usertype=mssql
        userhost=$(secret 'firethorn.user.host')
        userdata=$(secret 'firethorn.user.data')
        useruser=$(secret 'firethorn.user.user')
        userpass=$(secret 'firethorn.user.pass')

        datatype=mssql
        datahost=$(secret 'firethorn.data.host')
        datadata=$(secret 'firethorn.data.data')
        datauser=$(secret 'firethorn.data.user')
        datapass=$(secret 'firethorn.data.pass')

        tunneluser=$(secret 'ssh.tunnel.user')
        tunnelhost=$(secret 'ssh.tunnel.host')

        admingroup=Hyaenidae
        adminuser=Aardwolf
        adminpass=$(pwgen 20 1)

        guestgroup=Afrotheria
        guestuser=Hyrax
        guestpass=$(pwgen 20 1)

        tapresource=Wilhelmina
        tapschemadata=data-$(pwgen 10 1)
        tapschemauser=user-$(pwgen 10 1)
        tapschemapass=pass-$(pwgen 10 1)

EOF


# -----------------------------------------------------
# Determine our location.
#[user@builder]

    # 'local' if VM is inside UoE
    # 'remote' if VM is at outside UoE
    # TODO Change these to 'internal' and 'external'

    external=$(curl -4 --silent 'http://icanhazip.com/')

    EDINBURGH='129.215.*'

    if [[ ${external:?} == ${EDINBURGH} ]]
    then
        echo "Address [${external:?}] is in Edinburgh"
        #location=internal
        location=local
    else
        echo "Address [${external:?}] is not in Edinburgh"
        #location=external
        location=remote
    fi


# -----------------------------------------------------
# Link our compose config and start our test containers ...
#[user@builder]

    # Check the env file is linked !!

    pushd "${FIRETHORN_HOME:?}"

        ln -sf 'chain.properties' '.env'

        docker-compose \
            --file "${FIRETHORN_CODE:?}/docker/compose/tests/baryptera/baryptera-${location:?}.yml" \
            run \
                angela



# -----------------------------------------------------
# -----------------------------------------------------
# Separate shell on the host VM, locate the logs volume and tail the firethorn log.
#[user@virtual]

    sudo -s

    container=baryptera_gillian_1

    pushd $(
        docker inspect \
            "${container:?}" \
      | jq -r '
            .[].Mounts | .[] | select(.Destination == "/var/local/tomcat/logs") | .Source
            '
            )

    tail -f firethorn-debug.log

# -----------------------------------------------------
# -----------------------------------------------------
# Separate shell on the host VM, locate the logs volume and tail the ogsadai log.
#[user@virtual]

    sudo -s

    container=baryptera_jarmila_1

    pushd $(
        docker inspect \
            "${container:?}" \
      | jq -r '
            .[].Mounts | .[] | select(.Destination == "/var/local/tomcat/logs") | .Source
            '
            )

    tail -f ogsadai.log

# -----------------------------------------------------
# -----------------------------------------------------
# Run our Python tests ...
#[user@python]

import os
import uuid
import time
import firethorn as ftpy

#
# Create our firethorn client (using named param).
firethorn = ftpy.Firethorn(
    endpoint = os.environ.get(
        'endpoint'
        )
    )

#
# Login as the admin account.
firethorn.login(
    os.environ.get('adminuser'),
    os.environ.get('adminpass'),
    os.environ.get('admingroup')
    )

#
# Create a JdbcResource to connect to the ATLAS database.
atlas_jdbc = firethorn.firethorn_engine.create_jdbc_resource(
    "ATLAS JDBC resource",
    os.environ.get('datadata'),
    '*',
    os.environ.get('datatype'),
    os.environ.get('datahost'),
    os.environ.get('datauser'),
    os.environ.get('datapass')
    )
print(
    atlas_jdbc
    )

#
# Create an AdqlResource to represent the JdbcResource.
atlas_adql = firethorn.firethorn_engine.create_adql_resource(
    "ATLAS ADQL resource"
    )
print(
    atlas_adql
    )

#
# Import the target JdbcSchema into AdqlSchema.
schema_names = [
    "ATLASDR1"
    ]

for schema_name in schema_names:
    print(schema_name)
    jdbc_schema = atlas_jdbc.select_schema_by_name(
        schema_name,
        "dbo"
        )
    if (None != jdbc_schema):
        metadoc="https://raw.githubusercontent.com/wfau/metadata/master/metadocs/" + schema_name + "_TablesSchema.xml"
        adql_schema = atlas_adql.import_jdbc_schema(
            jdbc_schema,
            schema_name,
            metadoc=metadoc
            )

#
# Admin user
# -------- -------- -------- --------
# Normal user
#

#
# Login using a guest account.
firethorn.login(
    str(uuid.uuid4()),
    str(uuid.uuid4()),
    None
    )

#
# Create a new workspace.
workspace = firethorn.firethorn_engine.create_adql_resource(
    "Query resource"
    )

#
# Import the ATLAS schemas into our workspace
for schema in atlas_adql.select_schemas():
    workspace.import_adql_schema(
        schema
        )

#
# Create and run a query.
query_str = "SELECT TOP 1000 ra, dec FROM ATLASDR1.atlasSource"
query_obj = workspace.create_query(
    query_str,
    "COMPLETED",
    None,
    3000000
    )
print(
    query_obj
    )
print(
    query_obj.table()
    )
print(
    query_obj.table().count()
    )

#
# Iterate the metadata tree
for schema in atlas_adql.select_schemas():
    for table in schema.select_tables():
        print(
            "table  [{}][{}]".format(
                schema.name(),
                table.name()
                )
            )
        query_str = "SELECT TOP 10 * FROM {}.{}".format(
            schema.name(),
            table.name()
            )
        query_obj = workspace.create_query(
            query_str,
            "COMPLETED",
            None,
            3000000
            )
        py_table = query_obj.table().as_astropy()
        py_table.pprint()

#
# Run some queries in parallel
from concurrent.futures import ThreadPoolExecutor
import concurrent.futures
from datetime import datetime

query_str = "SELECT TOP 10000 ra, dec FROM ATLASDR1.atlasSource"

def do_query(workspace, query_str, limit, delay):
    before = datetime.now()
    query_obj = workspace.create_query(
        query_str,
        "COMPLETED",
        None,
        200000,
            {
            "adql.query.limit.rows"  : limit,
            "adql.query.delay.every" : delay
            }
        )
    after = datetime.now()
    return (
        (after - before),
        query_obj.json_object.get("results").get("count")
        )

def do_queries(workspace, query_str, threads, delay):
    with concurrent.futures.ThreadPoolExecutor(threads) as executor:
        futures = {
            executor.submit(
                do_query,
                workspace,
                query_str,
                limit,
                delay
                ): limit for limit in range(threads, 0, -1)
            }
        for future in concurrent.futures.as_completed(futures):
            print(
                future.result()[0],
                ':',
                future.result()[1]
                )

for loop in range(1, 10):
    for threads in range(1, 50):
        for delay in range(1000, -100, -100):
            print("---- ", loop, threads, delay)
            do_queries(
                workspace,
                query_str,
                threads,
                delay
                )


# -------- -------- -------- --------
# Bug testing.


#
# Triggering a ChaosMonkey Exception in the cleanUp() method doesn't cause an error (the query completes).
# http://wfau.metagrid.co.uk/code/firethorn/file/ab423c5da4f5/firethorn-ogsadai/activity/server/src/main/java/uk/ac/roe/wfau/firethorn/ogsadai/activity/server/sql/SQLQueryActivity.java#l469
params = {}
params.update({"firethorn.monkey.name" : "uk.ac.roe.wfau.firethorn.ogsadai.activity.server.sql.SQLQueryActivity"})
params.update({"firethorn.monkey.data" : "baivahP0"})

print(
    params
    )
query_str = "SELECT TOP 1000 ra, dec FROM ATLASDR1.atlasSource"
query_obj = workspace.create_query(
    query_str,
    "COMPLETED",
    None,
    3000000,
    params=params
    )
print(
    query_obj
    )

#
# Triggering a ChaosMonkey Exception between creating the Future and waiting for it doesn't cause the same problem (the query fails immediately).
# http://wfau.metagrid.co.uk/code/firethorn/file/ab423c5da4f5/firethorn-ogsadai/activity/server/src/main/java/uk/ac/roe/wfau/firethorn/ogsadai/activity/server/sql/SQLQueryActivity.java#l369
params = {}
params.update({"firethorn.monkey.name" : "uk.ac.roe.wfau.firethorn.ogsadai.activity.server.sql.SQLQueryActivity"})
params.update({"firethorn.monkey.data" : "uche2aNa"})

print(
    params
    )
query_str = "SELECT TOP 1000 ra, dec FROM ATLASDR1.atlasSource"
query_obj = workspace.create_query(
    query_str,
    "COMPLETED",
    None,
    3000000,
    params=params
    )
print(
    query_obj
    )

#
# Trigger a ChaosMonkey Exception inside the CallableStatement replicates the same symptoms as the issue we are tracking.
# http://wfau.metagrid.co.uk/code/firethorn/file/ab423c5da4f5/firethorn-ogsadai/activity/server/src/main/java/uk/ac/roe/wfau/firethorn/ogsadai/activity/server/sql/SQLQueryActivity.java#l414
params = {}
params.update({"firethorn.monkey.name" : "uk.ac.roe.wfau.firethorn.ogsadai.activity.server.sql.SQLQueryActivity$ChaoticCallableStatement"})
params.update({"firethorn.monkey.data" : "Eoph9xie"})

print(
    params
    )
query_str = "SELECT TOP 1000 ra, dec FROM ATLASDR1.atlasSource"
query_obj = workspace.create_query(
    query_str,
    "COMPLETED",
    None,
    3000000,
    params=params
    )
print(
    query_obj
    )






#
# Exit the Python shell

    Ctrl^D

# -----------------------------------------------------
# Shutdown our containers ...
#[user@virtual]

    docker-compose \
        --file "${FIRETHORN_CODE:?}/docker/compose/tests/baryptera/baryptera-local.yml" \
        down


