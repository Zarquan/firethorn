#
# <meta:header>
#   <meta:licence>
#     Copyright (c) 2016, ROE (http://www.roe.ac.uk/)
#
#     This information is free software: you can redistribute it and/or modify
#     it under the terms of the GNU General Public License as published by
#     the Free Software Foundation, either version 3 of the License, or
#     (at your option) any later version.
#
#     This information is distributed in the hope that it will be useful,
#     but WITHOUT ANY WARRANTY; without even the implied warranty of
#     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#     GNU General Public License for more details.
#  
#     You should have received a copy of the GNU General Public License
#     along with this program.  If not, see <http://www.gnu.org/licenses/>.
#   </meta:licence>
# </meta:header>
#
#

# -----------------------------------------------------
# Remove exiting containers and images.
#[user@desktop] 

    docker rm -f -v $(docker stop $(docker ps -aq))

    docker rmi -f $(docker images -q)

# -----------------------------------------------------
# Build our toolkit containers.
#[user@desktop] 

    source "${HOME:?}/firethorn.settings"
    pushd "${FIRETHORN_CODE:?}"

        docker build \
            --tag firethorn/fedora:21.1 \
            docker/fedora/21

        docker build \
            --tag firethorn/java:8.1 \
            docker/java/8

        docker build \
            --tag firethorn/tomcat:8.1 \
            docker/tomcat/8

        docker build \
            --tag firethorn/postgres:9 \
            docker/postgres/9

        docker build \
            --tag firethorn/builder:1.1 \
            docker/builder

        docker build \
            --tag firethorn/docker-proxy:1.1 \
            docker/docker-proxy

        docker build \
            --tag firethorn/sql-proxy:1.1 \
            docker/sql-proxy

        docker build \
            --tag firethorn/sql-tunnel:1.1 \
            docker/sql-tunnel

        docker build \
            --tag firethorn/ssh-client:1.1 \
            docker/ssh-client

    popd

# -----------------------------------------------------
# Load our secret function.
#[user@desktop] 

    source ${HOME:?}/secret.sh

    secret 'ping'

# -----------------------------------------------------
# Get our branch and version number.
#[user@desktop] 

    source "${HOME:?}/firethorn.settings"
    pushd "${FIRETHORN_CODE:?}"

        branch=$(hg branch)

        source 'bin/util.sh'
        version=$(getversion)

    popd

# -----------------------------------------------------
# Configure our docker chain.
#[user@desktop] 

    cat > "${HOME:?}/chain.properties" << EOF

    metaname=bethany
    username=patricia
    dataname=elayne
    ogsaname=jarmila
    firename=gillian

    metalink=albert
    userlink=edward
    datalink=sebastien
    ogsalink=timothy
    firelink=peter

    metatype=pgsql
    metadata=postgres
    metauser=$(pwgen 20 1)
    metapass=$(pwgen 20 1)
    metadriver=org.postgresql.Driver

    usertype=mssql
    userhost=$(secret 'firethorn.user.host')
    userdata=$(secret 'firethorn.user.data')
    useruser=$(secret 'firethorn.user.user')
    userpass=$(secret 'firethorn.user.pass')
    userdriver=net.sourceforge.jtds.jdbc.Driver

    datatype=mssql
    datahost=$(secret 'firethorn.data.host')
    datadata=$(secret 'firethorn.data.data')
    datauser=$(secret 'firethorn.data.user')
    datapass=$(secret 'firethorn.data.pass')
    datadriver=net.sourceforge.jtds.jdbc.Driver

    tunneluser=$(secret 'ssh.tunnel.user')
    tunnelhost=$(secret 'ssh.tunnel.host')

EOF

# -----------------------------------------------------
# Create our FireThorn config.
#[user@desktop] 

    source "${HOME:?}/chain.properties"

    cat > "${HOME:?}/firethorn.properties" << EOF

firethorn.ogsadai.endpoint=http://${ogsalink:?}:8080/ogsadai/services

firethorn.meta.type=${metatype:?}
firethorn.meta.url=jdbc:postgresql://${metalink:?}/${metadata:?}
firethorn.meta.user=${metauser:?}
firethorn.meta.pass=${metapass:?}
firethorn.meta.driver=${metadriver:?}

firethorn.user.type=${usertype:?}
firethorn.user.url=jdbc:jtds:sqlserver://${userlink:?}/${userdata:?}
firethorn.user.user=${useruser:?}
firethorn.user.pass=${userpass:?}
firethorn.user.driver=${userdriver:?}

EOF

    chmod a+r "${HOME:?}/firethorn.properties" 
    chcon -t svirt_sandbox_file_t "${HOME:?}/firethorn.properties" 

# -----------------------------------------------------
# Start our userdata ambassador.
#[user@desktop] 

    source "${HOME:?}/chain.properties"
    docker run \
        --detach \
        --interactive \
        --name "${username:?}" \
        --env  "tunneluser=${tunneluser:?}" \
        --env  "tunnelhost=${tunnelhost:?}" \
        --env  "targethost=${userhost:?}" \
        --volume "${SSH_AUTH_SOCK}:/tmp/ssh_auth_sock" \
        firethorn/sql-tunnel:1.1

# -----------------------------------------------------
# Start our science data ambassador.
#[user@desktop] 

    source "${HOME:?}/chain.properties"
    docker run \
        --detach \
        --interactive \
        --name "${dataname:?}" \
        --env  "tunneluser=${tunneluser:?}" \
        --env  "tunnelhost=${tunnelhost:?}" \
        --env  "targethost=${datahost:?}" \
        --volume "${SSH_AUTH_SOCK}:/tmp/ssh_auth_sock" \
        firethorn/sql-tunnel:1.1

# -----------------------------------------------------
# Start our PostgreSQL metadata container.
#[user@desktop] 

    source "${HOME:?}/chain.properties"
    docker run \
        --detach \
        --name "${metaname:?}" \
        --env "POSTGRES_USER=${metauser:?}" \
        --env "POSTGRES_PASSWORD=${metapass:?}" \
        postgres


# -----------------------------------------------------
# Start our docker-proxy container.
#[user@desktop] 

    docker run \
        --detach \
        --name "docker-proxy" \
        --volume /var/run/docker.sock:/var/run/docker.sock \
        firethorn/docker-proxy:1.1

    sleep 1
    dockerip=$(docker inspect -f '{{.NetworkSettings.IPAddress}}' docker-proxy)

    echo "${dockerip:?}"
    curl "http://${dockerip:?}:2375/version"

# -----------------------------------------------------
# Build our Java code.
#[user@desktop] 

    source "${HOME:?}/firethorn.settings"
    pushd "${FIRETHORN_CODE:?}"

        mvn clean install
        
    popd

# -----------------------------------------------------
# Build our webapp containers.
#[user@desktop] 

    source "${HOME:?}/firethorn.settings"
    pushd "${FIRETHORN_CODE:?}"

        pushd firethorn-ogsadai/webapp
            mvn -D "docker.host=http://${dockerip:?}:2375" docker:package
        popd
        
        pushd firethorn-webapp
            mvn -D "docker.host=http://${dockerip:?}:2375" docker:package
        popd

    popd

# -----------------------------------------------------
# Stop exiting webapp containers.
#[user@desktop] 

    docker stop ${ogsaname:?}
    docker rm -f -v ${ogsaname:?}

    docker stop ${firename:?}
    docker rm -f -v ${firename:?}

# -----------------------------------------------------
# Start our OGSA-DAI container.
#[user@desktop] 

    source "${HOME:?}/chain.properties"

    docker run \
        --detach \
        --name "${ogsaname:?}" \
        --link "${dataname:?}:${datalink:?}" \
        --link "${username:?}:${userlink:?}" \
        --volume /etc/localtime:/etc/localtime:ro \
        "firethorn/ogsadai:${version:?}"

# -----------------------------------------------------
# Start our FireThorn container.
#[user@desktop] 

    source "${HOME:?}/chain.properties"

    properties=${HOME:?}/firethorn.properties

    docker run \
        --detach \
        --name "${firename:?}" \
        --link "${ogsaname:?}:${ogsalink:?}" \
        --link "${metaname:?}:${metalink:?}" \
        --link "${dataname:?}:${datalink:?}" \
        --link "${username:?}:${userlink:?}" \
        --volume "${properties:?}:/etc/firethorn.properties" \
        --volume /etc/localtime:/etc/localtime:ro \
        "firethorn/firethorn:${version:?}"

# -----------------------------------------------------
# Check the logs ..
#[user@desktop] 

# Separate terminal
# source "${HOME:?}/chain.properties"
# docker exec -it "${firename:?}" tail -f logs/firethorn.log 


# Separate terminal
# source "${HOME:?}/chain.properties"
# docker exec -it "${ogsaname:?}" tail -f logs/ogsadai.log 

# -----------------------------------------------------
# Build our tester container.
#[user@desktop] 

    source "${HOME:?}/firethorn.settings"
    pushd "${FIRETHORN_CODE:?}"

        source "bin/util.sh"

        docker build \
            --tag firethorn/tester:1.1 \
            integration/tester

    popd

# -----------------------------------------------------
# Start our tester container.
#[user@desktop] 

    source "${HOME:?}/chain.properties"
    docker run \
        --rm \
        --tty \
        --interactive \
        --env "datadata=${datadata:?}" \
        --env "datalink=${datalink:?}" \
        --env "datauser=${datauser:?}" \
        --env "datapass=${datapass:?}" \
        --env "datadriver=${datadriver:?}" \
        --env "endpointurl=http://${firelink:?}:8080/firethorn" \
        --link "${firename:?}:${firelink:?}" \
        --volume /etc/localtime:/etc/localtime:ro \
        "firethorn/tester:1.1" \
        bash

# -----------------------------------------------------
# Configure our identity.
#[root@tester]

        identity=${identity:-$(date '+%H:%M:%S')}
        community=${community:-$(date '+%A %-d %B %Y')}

        source "bin/01-01-init-rest.sh"

# -----------------------------------------------------
# Check the system info.
#[root@tester]

        curl \
            --header "firethorn.auth.identity:${identity:?}" \
            --header "firethorn.auth.community:${community:?}" \
            "${endpointurl:?}/system/info" \
            | bin/pp | tee system-info.json

# -----------------------------------------------------
# AstroGrid DAL service doesn't handle fully qualified names :-(
# -----------------------------------------------------

# -----------------------------------------------------
# Load the ATLASDR1 resource.
#[root@tester]

        database=ATLASDR1
        
        source "bin/02-02-create-jdbc-space.sh" \
            'Atlas JDBC conection' \
            "jdbc:jtds:sqlserver://${datalink:?}/${database:?}" \
            "${datauser:?}" \
            "${datapass:?}" \
            "${datadriver:?}" \
            '*'
        atlasjdbc=${jdbcspace:?}

        source "bin/03-01-create-adql-space.sh" 'Atlas ADQL workspace'
        atlasadql=${adqlspace:?}

        source "bin/03-04-import-jdbc-metadoc.sh" "${atlasjdbc:?}" "${atlasadql:?}" 'ATLASDR1' 'dbo' "meta/ATLASDR1_AtlasSource.xml"

# -----------------------------------------------------
# Create the GAVO TWOMASS resource.
#[root@tester]

        #
        # Create the IvoaResource
        source "bin/02-03-create-ivoa-space.sh" \
            'GAVO TAP service' \
            'http://dc.zah.uni-heidelberg.de/__system__/tap/run/tap'

        #
        # Import the static VOSI file
        vosifile='vosi/gavo/gavo-tableset.xml'
        curl \
            --header "firethorn.auth.identity:${identity:?}" \
            --header "firethorn.auth.community:${community:?}" \
            --form   "vosi.tableset=@${vosifile:?}" \
            "${endpointurl:?}/${ivoaspace:?}/vosi/import" \
            | bin/pp

        #
        # Find the twomass schema
        gavospace=${ivoaspace:?}
        schemaname=twomass
        curl \
            --header "firethorn.auth.identity:${identity:?}" \
            --header "firethorn.auth.community:${community:?}" \
            --data   "ivoa.resource.schema.name=${schemaname:?}" \
            "${endpointurl:?}/${gavospace:?}/schemas/select" \
            | bin/pp | tee gavo-schema.json

        gavoschema=$(
            cat gavo-schema.json | self
            )

# -----------------------------------------------------
# Create our query workspace
#[root@tester]

        source "bin/04-01-create-query-space.sh"  'Test workspace'
        source "bin/04-03-import-query-schema.sh" "${atlasadql:?}"   'ATLASDR1' 'atlas'

        #
        # BUG - the param names are different for adql and ivoa schema/select 
        #source "bin/04-03-import-query-schema.sh" "${twomassadql:?}" 'twomass'  'twomass'

        adqlname=twomass
        curl \
            --header "firethorn.auth.identity:${identity:?}" \
            --header "firethorn.auth.community:${community:?}" \
            --data   "urn:adql.copy.depth=${adqlcopydepth:-THIN}" \
            --data   "adql.resource.schema.import.name=${adqlname:?}" \
            --data   "adql.resource.schema.import.base=${gavoschema:?}" \
            "${endpointurl:?}/${queryspace:?}/schemas/import" \
            | bin/pp | tee query-schema.json

# -----------------------------------------------------
# Test query ...
#[root@tester]

        curl \
            --silent \
            --header "firethorn.auth.identity:${identity:?}" \
            --header "firethorn.auth.community:${community:?}" \
            --data "adql.query.input=SELECT TOP 2000 raj2000, dej2000 FROM twomass.data" \
            --data "adql.query.status.next=COMPLETED" \
            --data "adql.query.wait.time=600000" \
            "${endpointurl:?}/${queryspace:?}/queries/create" \
            | bin/pp | tee blue-query.json

# --------------------------------------
# Create the GAIA TWOMASS resource.
#[root@tester]

        #
        # Create the IvoaResource
        source "bin/02-03-create-ivoa-space.sh" \
            'GAIA TAP service' \
            'https://gaia.esac.esa.int/tap-server/tap'

        #
        # Import the static VOSI file
        vosifile='vosi/gaia/gaia-tableset.xml'
        curl \
            --header "firethorn.auth.identity:${identity:?}" \
            --header "firethorn.auth.community:${community:?}" \
            --form   "vosi.tableset=@${vosifile:?}" \
            "${endpointurl:?}/${ivoaspace:?}/vosi/import" \
            | bin/pp

        #
        # Find the twomass schema
        gaiaspace=${ivoaspace:?}
        schemaname=public
        curl \
            --header "firethorn.auth.identity:${identity:?}" \
            --header "firethorn.auth.community:${community:?}" \
            --data   "ivoa.resource.schema.name=${schemaname:?}" \
            "${endpointurl:?}/${gaiaspace:?}/schemas/select" \
            | bin/pp | tee gaia-schema.json

        gaiaschema=$(
            cat gaia-schema.json | self
            )

# -----------------------------------------------------
# Create our query workspace
#[root@tester]

        source "bin/04-01-create-query-space.sh"  'Test workspace'
        source "bin/04-03-import-query-schema.sh" "${atlasadql:?}"   'ATLASDR1' 'atlas'

        #
        # BUG - the param names are different for adql and ivoa schema/select 
        #source "bin/04-03-import-query-schema.sh" "${twomassadql:?}" 'twomass'  'twomass'

        adqlname=public
        curl \
            --header "firethorn.auth.identity:${identity:?}" \
            --header "firethorn.auth.community:${community:?}" \
            --data   "urn:adql.copy.depth=${adqlcopydepth:-THIN}" \
            --data   "adql.resource.schema.import.name=${adqlname:?}" \
            --data   "adql.resource.schema.import.base=${gaiaschema:?}" \
            "${endpointurl:?}/${queryspace:?}/schemas/import" \
            | bin/pp | tee query-schema.json

# -----------------------------------------------------
# Test query ...
#[root@tester]

        curl \
            --silent \
            --header "firethorn.auth.identity:${identity:?}" \
            --header "firethorn.auth.community:${community:?}" \
            --data "adql.query.input=SELECT TOP 2000 ra, dec FROM public.tmass_original_valid" \
            --data "adql.query.status.next=COMPLETED" \
            --data "adql.query.wait.time=600000" \
            "${endpointurl:?}/${queryspace:?}/queries/create" \
            | bin/pp | tee blue-query.json

# -----------------------------------------------------
# Test query ...
#[root@tester]

        curl \
            --silent \
            --header "firethorn.auth.identity:${identity:?}" \
            --header "firethorn.auth.community:${community:?}" \
            --data "adql.query.input=SELECT TOP 2000 ra, dec FROM atlas.atlasSource" \
            --data "adql.query.status.next=COMPLETED" \
            --data "adql.query.wait.time=600000" \
            "${endpointurl:?}/${queryspace:?}/queries/create" \
            | bin/pp | tee blue-query.json

