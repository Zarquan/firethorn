#
# <meta:header>
#   <meta:licence>
#     Copyright (c) 2016, ROE (http://www.roe.ac.uk/)
#
#     This information is free software: you can redistribute it and/or modify
#     it under the terms of the GNU General Public License as published by
#     the Free Software Foundation, either version 3 of the License, or
#     (at your option) any later version.
#
#     This information is distributed in the hope that it will be useful,
#     but WITHOUT ANY WARRANTY; without even the implied warranty of
#     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#     GNU General Public License for more details.
#  
#     You should have received a copy of the GNU General Public License
#     along with this program.  If not, see <http://www.gnu.org/licenses/>.
#   </meta:licence>
# </meta:header>
#
#

# -----------------------------------------------------
# Create a new VM.
#[user@trop02]

    createvm

        INFO : Node name [Araybwyn]
        INFO : Base name [fedora-24-docker-32G-20170113.qcow]
        INFO : Base path [/var/lib/libvirt/images/base/fedora-24-docker-32G-20170113.qcow]
        INFO : Disc name [Araybwyn.qcow]
        INFO : Disc size [32GiB]

# -----------------------------------------------------
# Remove old version of compose.
#[root@virtual]

    dnf -y remove docker-compose

# -----------------------------------------------------
# Install latest version of compose.
#[root@virtual]

    curl -L https://github.com/docker/compose/releases/download/1.11.1/docker-compose-`uname -s`-`uname -m` > /usr/bin/docker-compose
    chmod +x /usr/bin/docker-compose





# -----------------------------------------------------
# Load our secret function.
#[user@virtual]

    vi ${HOME:?}/secret.sh

        ....

    source ${HOME:?}/secret.sh
    secret 'ping'

# -----------------------------------------------------
# Configure our build version and instance name.
#[user@virtual] 

    branch=default
    version=2.1.4
    buildtag=${version:?}

    instance=$(pwgen 8 1)

# -----------------------------------------------------
# Create our chain config.
#[user@virtual] 

    cat > "${HOME:?}/chain.properties" << EOF

    metaname=bethany
    username=patricia
    dataname=elayne
    ogsaname=jarmila
    firename=gillian
    testname=aaliyah

    metatype=pgsql
    metadata=postgres
    metauser=$(pwgen 20 1)
    metapass=$(pwgen 20 1)
    metadriver=org.postgresql.Driver

    usertype=mssql
    userhost=$(secret 'firethorn.user.host')
    userdata=$(secret 'firethorn.user.data')
    useruser=$(secret 'firethorn.user.user')
    userpass=$(secret 'firethorn.user.pass')
    userdriver=net.sourceforge.jtds.jdbc.Driver

    datatype=mssql
    datahost=$(secret 'firethorn.data.host')
    datadata=$(secret 'firethorn.data.data')
    datauser=$(secret 'firethorn.data.user')
    datapass=$(secret 'firethorn.data.pass')
    datadriver=net.sourceforge.jtds.jdbc.Driver

    tunneluser=$(secret 'ssh.tunnel.user')
    tunnelhost=$(secret 'ssh.tunnel.host')

EOF

# -----------------------------------------------------
# Create our FireThorn config.
#[user@virtual] 

    source "${HOME:?}/chain.properties"
    cat > "${HOME:?}/firethorn.properties" << EOF

firethorn.ogsadai.endpoint=http://${ogsaname:?}:8080/ogsadai/services

firethorn.meta.type=${metatype:?}
firethorn.meta.url=jdbc:postgresql://${metaname:?}/${metadata:?}
firethorn.meta.user=${metauser:?}
firethorn.meta.pass=${metapass:?}
firethorn.meta.driver=${metadriver:?}

firethorn.user.type=${usertype:?}
firethorn.user.url=jdbc:jtds:sqlserver://${username:?}/${userdata:?}
firethorn.user.user=${useruser:?}
firethorn.user.pass=${userpass:?}
firethorn.user.driver=${userdriver:?}

firethorn.ogsa.resource.scan=PT1M

EOF

    chmod a+r "${HOME:?}/firethorn.properties" 
    chcon -t svirt_sandbox_file_t "${HOME:?}/firethorn.properties" 

# -----------------------------------------------------
# Create our tester config.
#[user@virtual] 

    source "${HOME:?}/chain.properties"
    cat > "${HOME:?}/tester.properties" << EOF

        datadata=${datadata:?}
        dataname=${dataname:?}
        datauser=${datauser:?}
        datapass=${datapass:?}
        datadriver=${datadriver:?}
        endpointurl=http://${firename:?}:8080/firethorn

EOF

    chmod a+r "${HOME:?}/tester.properties" 
    chcon -t svirt_sandbox_file_t "${HOME:?}/tester.properties" 

# -----------------------------------------------------
# Create our composer env file.
#[user@virtual] 

    source "${HOME:?}/chain.properties"
    source "${HOME:?}/firethorn.settings"

    cat > "${HOME:?}/.env" << EOF
buildtag=${buildtag:?}

metauser=${metauser:?}
metapass=${metapass:?}

datahost=${datahost:?}
userhost=${userhost:?}

tunneluser=${tunneluser:?}
tunnelhost=${tunnelhost:?}

EOF

# -----------------------------------------------------
# Get acopy of our compose file.
#[user@virtual] 

    composit=${HOME:?}/compose
    mkdir ${composit:?}
    pushd ${composit:?}

        wget http://wfau.metagrid.co.uk/code/firethorn/raw-file/5327b0eaf0a1/docker/compose/testing.yml

    popd

# -----------------------------------------------------
# Run our tester.
#[user@virtual] 

    export buildtag
    docker-compose \
        --file "${composit:?}/testing.yml" \
        --project ${instance:?} \
        run tester 

# -----------------------------------------------------
# Load our configuration.
#[root@tester]

        source /etc/tester.properties

# -----------------------------------------------------
# Configure our identity.
#[root@tester]

        identity=${identity:-$(date '+%H:%M:%S')}
        community=${community:-$(date '+%A %-d %B %Y')}

        source "bin/01-01-init-rest.sh"

# -----------------------------------------------------
# Check the system info.
#[root@tester]

        curl \
            --silent \
            --header "firethorn.auth.identity:${identity:?}" \
            --header "firethorn.auth.community:${community:?}" \
            "${endpointurl:?}/system/info" \
            | bin/pp | tee /tmp/system-info.json

# -----------------------------------------------------
# Load the local TWOMASS resource.
#[root@tester]

        source "bin/02-02-create-jdbc-space.sh" \
            'TWOMASS JDBC conection' \
            "jdbc:jtds:sqlserver://${dataname:?}/TWOMASS" \
            "${datauser:?}" \
            "${datapass:?}" \
            "${datadriver:?}" \
            '*'
        wfaujdbc=${jdbcspace:?}

        source "bin/03-01-create-adql-space.sh" 'TWOMASS ADQL workspace'
        wfauadql=${adqlspace:?}

        source "bin/03-04-import-jdbc-metadoc.sh" "${wfaujdbc:?}" "${wfauadql:?}" 'TWOMASS' 'dbo' "meta/TWOMASS_TablesSchema.xml"

# -----------------------------------------------------
# Create a workspace and add the local TWOMASS schema.
#[root@tester]

        source "bin/04-01-create-query-space.sh"  'Test workspace'
        source "bin/04-03-import-query-schema.sh" "${wfauadql:?}" 'TWOMASS' 'wfau'

# -----------------------------------------------------
# Test queries ...
#[root@tester]

        curl \
            --silent \
            --header "firethorn.auth.identity:${identity:?}" \
            --header "firethorn.auth.community:${community:?}" \
            --data "adql.query.input=SELECT TOP 2000 designation, ra, dec FROM wfau.twomass_psc WHERE (ra BETWEEN 0 AND 0.5) AND (dec BETWEEN 0 AND 0.5)" \
            --data "adql.query.status.next=COMPLETED" \
            --data "adql.query.wait.time=600000" \
            "${endpointurl:?}/${queryspace:?}/queries/create" \
            | bin/pp | tee /tmp/wfau-query.json

        #
        # Get URL for the results as VOTable
        wfaudata=$(cat /tmp/wfau-query.json | votable)

        #
        # Get the results as VOTable files
        curl --silent "${wfaudata:?}" | xmlstarlet fo | tee /tmp/wfau-data.xml

        #
        # Remove XML namespaces
        sed -i 's#<VOTABLE[^>]*>#<VOTABLE>#' /tmp/wfau-data.xml

        #
        # Select a specific row.
        xmlstarlet sel -t -c "//TR[TD='00012764+0028492']" /tmp/wfau-data.xml | xmlstarlet fo


# -----------------------------------------------------
# Create the GAVO TWOMASS resource.
#[root@tester]

        #
        # Create the IvoaResource
        source "bin/02-03-create-ivoa-space.sh" \
            'GAVO TAP service' \
            'http://dc.zah.uni-heidelberg.de/__system__/tap/run/tap'
        gavoivoa=${ivoaspace:?}

        #
        # Import the static VOSI file
        vosifile='vosi/gavo/gavo-tableset.xml'
        curl \
            --header "firethorn.auth.identity:${identity:?}" \
            --header "firethorn.auth.community:${community:?}" \
            --form   "vosi.tableset=@${vosifile:?}" \
            "${endpointurl:?}/${gavoivoa:?}/vosi/import" \
            | bin/pp

        #
        # Find the Gavo twomass schema
        findname=twomass
        curl \
            --header "firethorn.auth.identity:${identity:?}" \
            --header "firethorn.auth.community:${community:?}" \
            --data   "ivoa.resource.schema.name=${findname:?}" \
            "${endpointurl:?}/${gavoivoa:?}/schemas/select" \
            | bin/pp | tee /tmp/gavo-schema.json

        gavoschema=$(
            cat /tmp/gavo-schema.json | self
            )

# --------------------------------------
# Create the GAIA TAP resource.
#[root@tester]

        #
        # Create the IvoaResource
        source "bin/02-03-create-ivoa-space.sh" \
            'GAIA TAP service' \
            'http://gea.esac.esa.int/tap-server/tap'
        gaiaivoa=${ivoaspace:?}

        #
        # Import the static VOSI file
        vosifile='vosi/gaia/gaia-tableset.xml'
        curl \
            --header "firethorn.auth.identity:${identity:?}" \
            --header "firethorn.auth.community:${community:?}" \
            --form   "vosi.tableset=@${vosifile:?}" \
            "${endpointurl:?}/${gaiaivoa:?}/vosi/import" \
            | bin/pp

        #
        # Find the Gaia DR1 schema
        findname=gaiadr1
        curl \
            --header "firethorn.auth.identity:${identity:?}" \
            --header "firethorn.auth.community:${community:?}" \
            --data   "ivoa.resource.schema.name=${findname:?}" \
            "${endpointurl:?}/${gaiaivoa:?}/schemas/select" \
            | bin/pp | tee /tmp/gaia-schema.json

        gaiaschema=$(
            cat /tmp/gaia-schema.json | self
            )

# -----------------------------------------------------
# Add the GAVO TWOMASS schema to our workspace.
#[root@tester]

        gavoname=gavo
        curl \
            --header "firethorn.auth.identity:${identity:?}" \
            --header "firethorn.auth.community:${community:?}" \
            --data   "urn:adql.copy.depth=${adqlcopydepth:-THIN}" \
            --data   "adql.resource.schema.import.name=${gavoname:?}" \
            --data   "adql.resource.schema.import.base=${gavoschema:?}" \
            "${endpointurl:?}/${queryspace:?}/schemas/import" \
            | bin/pp | tee /tmp/query-schema.json

# -----------------------------------------------------
# Add the Gaia DR1 schema to our workspace.
#[root@tester]

        gaianame=gaia
        curl \
            --header "firethorn.auth.identity:${identity:?}" \
            --header "firethorn.auth.community:${community:?}" \
            --data   "urn:adql.copy.depth=${adqlcopydepth:-THIN}" \
            --data   "adql.resource.schema.import.name=${gaianame:?}" \
            --data   "adql.resource.schema.import.base=${gaiaschema:?}" \
            "${endpointurl:?}/${queryspace:?}/schemas/import" \
            | bin/pp | tee /tmp/query-schema.json

# -----------------------------------------------------
# Test queries ...
#[root@tester]

        curl \
            --silent \
            --header "firethorn.auth.identity:${identity:?}" \
            --header "firethorn.auth.community:${community:?}" \
            --data "adql.query.input=SELECT designation, ra, dec FROM wfau.twomass_psc WHERE (ra BETWEEN 0 AND 0.5) AND (dec BETWEEN 0 AND 0.5)" \
            --data "adql.query.status.next=COMPLETED" \
            --data "adql.query.wait.time=600000" \
            "${endpointurl:?}/${queryspace:?}/queries/create" \
            | bin/pp | tee /tmp/wfau-query.json

        curl \
            --silent \
            --header "firethorn.auth.identity:${identity:?}" \
            --header "firethorn.auth.community:${community:?}" \
            --data "adql.query.input=SELECT mainid AS designation, raj2000 AS ra, dej2000 AS dec FROM gavo.data WHERE (raj2000 BETWEEN 0 AND 0.5) AND (dej2000 BETWEEN 0 AND 0.5)" \" \
            --data "adql.query.status.next=COMPLETED" \
            --data "adql.query.wait.time=600000" \
            "${endpointurl:?}/${queryspace:?}/queries/create" \
            | bin/pp | tee /tmp/gavo-query.json

        curl \
            --silent \
            --header "firethorn.auth.identity:${identity:?}" \
            --header "firethorn.auth.community:${community:?}" \
            --data "adql.query.input=SELECT designation, ra, dec  FROM gaia.tmass_original_valid WHERE (ra BETWEEN 0 AND 0.5) AND (dec BETWEEN 0 AND 0.5)" \
            --data "adql.query.status.next=COMPLETED" \
            --data "adql.query.wait.time=600000" \
            "${endpointurl:?}/${queryspace:?}/queries/create" \
            | bin/pp | tee /tmp/gaia-query.json

        #
        # Get URLs for the results as VOTable
        wfaudata=$(cat /tmp/wfau-query.json | votable)
        gavodata=$(cat /tmp/gavo-query.json | votable)
        gaiadata=$(cat /tmp/gaia-query.json | votable)

        #
        # Get the results as VOTable files
        curl --silent "${wfaudata:?}" | xmlstarlet fo > /tmp/wfau-data.xml
        curl --silent "${gavodata:?}" | xmlstarlet fo > /tmp/gavo-data.xml
        curl --silent "${gaiadata:?}" | xmlstarlet fo > /tmp/gaia-data.xml

        #
        # Remove XML namespaces
        sed -i 's#<VOTABLE[^>]*>#<VOTABLE>#' /tmp/wfau-data.xml
        sed -i 's#<VOTABLE[^>]*>#<VOTABLE>#' /tmp/gavo-data.xml
        sed -i 's#<VOTABLE[^>]*>#<VOTABLE>#' /tmp/gaia-data.xml

        #
        # Select a specific row.
        xmlstarlet sel -t -c "//TR[TD='00012764+0028492']" /tmp/wfau-data.xml | xmlstarlet fo
        xmlstarlet sel -t -c "//TR[TD='00012764+0028492']" /tmp/gavo-data.xml | xmlstarlet fo
        xmlstarlet sel -t -c "//TR[TD='00012764+0028492']" /tmp/gaia-data.xml | xmlstarlet fo

# -----------------------------------------------------
# Create our join query ...
#[root@tester]

    cat > /tmp/join-query.adql << EOF

    SELECT
        gaia.tmass_best_neighbour.original_ext_source_id AS gaia_ident,
        wfau.twomass_psc.designation                     AS wfau_ident,

        gaia.tmass_best_neighbour.source_id              AS best_source_id,
        gaia.gaia_source.source_id                       AS gaia_source_id,

        wfau.twomass_psc.ra                              AS wfau_ra,
        gaia.gaia_source.ra                              AS gaia_ra,

        wfau.twomass_psc.ra - gaia.gaia_source.ra        AS delta_ra,

        wfau.twomass_psc.dec                             AS wfau_dec,
        gaia.gaia_source.dec                             AS gaia_dec,

        wfau.twomass_psc.dec - gaia.gaia_source.dec      AS delta_dec

    FROM
        gaia.gaia_source,
        gaia.tmass_best_neighbour,
        wfau.twomass_psc

    WHERE
        gaia.tmass_best_neighbour.source_id = gaia.gaia_source.source_id
    AND
        gaia.tmass_best_neighbour.original_ext_source_id = wfau.twomass_psc.designation
    AND
        gaia.gaia_source.ra  BETWEEN 0 AND 1.25
    AND
        gaia.gaia_source.dec BETWEEN 0 AND 1.25
    AND
        wfau.twomass_psc.ra  BETWEEN 0 AND 1.25
    AND
        wfau.twomass_psc.dec BETWEEN 0 AND 1.25

EOF

# -----------------------------------------------------
# Execute our join query.
#[root@tester]

        curl \
            --silent \
            --header "firethorn.auth.identity:${identity:?}" \
            --header "firethorn.auth.community:${community:?}" \
            --data-urlencode "adql.query.input@/tmp/join-query.adql" \
            --data "adql.query.status.next=COMPLETED" \
            --data "adql.query.wait.time=600000" \
            "${endpointurl:?}/${queryspace:?}/queries/create" \
            | bin/pp | tee /tmp/join-query.json

        #
        # Get the URL for the results as VOTable
        joindata=$(cat /tmp/join-query.json | votable)

        #
        # Get the results as VOTable
        curl --silent "${joindata:?}" | xmlstarlet fo > /tmp/join-data.xml

        #
        # Remove XML namespaces
        sed -i 's#<VOTABLE[^>]*>#<VOTABLE>#' /tmp/join-data.xml

        #
        # Select a specific row.
        xmlstarlet sel -t -c "//TR[TD='00012764+0028492']" /tmp/join-data.xml | xmlstarlet fo


# -----------------------------------------------------
# Load the local ATLAS resource.
#[root@tester]

        source "bin/02-02-create-jdbc-space.sh" \
            'ATLAS JDBC conection' \
            "jdbc:jtds:sqlserver://${dataname:?}/ATLASDR1" \
            "${datauser:?}" \
            "${datapass:?}" \
            "${datadriver:?}" \
            '*'
        atlasjdbc=${jdbcspace:?}

        source "bin/03-01-create-adql-space.sh" 'ATLAS ADQL workspace'
        atlasadql=${adqlspace:?}

        source "bin/03-04-import-jdbc-metadoc.sh" "${atlasjdbc:?}" "${atlasadql:?}" 'ATLASDR1' 'dbo' "meta/ATLASDR1_TablesSchema.xml"
        source "bin/03-04-import-jdbc-metadoc.sh" "${atlasjdbc:?}" "${atlasadql:?}" 'ATLASDR2' 'dbo' "meta/ATLASDR2_TablesSchema.xml"

# -----------------------------------------------------
# Create a workspace and add ADQL schemas.
#[root@tester]

        source "bin/04-01-create-query-space.sh"  'Test workspace'
        source "bin/04-03-import-query-schema.sh" "${wfauadql:?}" 'TWOMASS'  'TWOMASS'
        source "bin/04-03-import-query-schema.sh" "${atlasadql:?}" 'ATLASDR1' 'ATLASDR1'

        gavoname=gavo
        curl \
            --header "firethorn.auth.identity:${identity:?}" \
            --header "firethorn.auth.community:${community:?}" \
            --data   "urn:adql.copy.depth=${adqlcopydepth:-THIN}" \
            --data   "adql.resource.schema.import.name=${gavoname:?}" \
            --data   "adql.resource.schema.import.base=${gavoschema:?}" \
            "${endpointurl:?}/${queryspace:?}/schemas/import" \
            | bin/pp | tee /tmp/query-schema.json

        gaianame=gaia
        curl \
            --header "firethorn.auth.identity:${identity:?}" \
            --header "firethorn.auth.community:${community:?}" \
            --data   "urn:adql.copy.depth=${adqlcopydepth:-THIN}" \
            --data   "adql.resource.schema.import.name=${gaianame:?}" \
            --data   "adql.resource.schema.import.base=${gaiaschema:?}" \
            "${endpointurl:?}/${queryspace:?}/schemas/import" \
            | bin/pp | tee /tmp/query-schema.json

# -----------------------------------------------------
# Run our test queries.
#[root@tester]

    cat > /tmp/test-query.adql << EOF
SELECT
    umgPntErr,
    gmrPntErr,
    rmiPntErr
FROM
    (
    SELECT
        *
    FROM
        atlasSource
    WHERE
        ra  BETWEEN 0 AND 1.25
    AND
        dec BETWEEN 0 AND 1.25
    ) AS albert
WHERE
    umgPntErr > 0
AND
    gmrPntErr > 0
AND
    rmiPntErr > 0
EOF

    cat > /tmp/test-query.adql << EOF
SELECT
    umgPntErr,
    gmrPntErr,
    rmiPntErr
FROM
    atlasSource
WHERE
    ra  BETWEEN 0 AND 1.25
AND
    dec BETWEEN 0 AND 1.25
EOF

        curl \
            --silent \
            --header "firethorn.auth.identity:${identity:?}" \
            --header "firethorn.auth.community:${community:?}" \
            --data-urlencode "adql.query.input@/tmp/test-query.adql" \
            --data "adql.query.status.next=COMPLETED" \
            --data "adql.query.wait.time=600000" \
            "${endpointurl:?}/${queryspace:?}/queries/create" \
            | bin/pp | tee /tmp/test-query.json

        testdata=$(cat /tmp/test-query.json | votable)
        curl --silent "${testdata:?}" | xmlstarlet fo | tee /tmp/test-data.xml









    cat > /tmp/test-query.adql << EOF
SELECT
    distanceMins
FROM
    (
    SELECT TOP 10
        *
    FROM
        atlasSourceXDR7PhotoObj
    WHERE
        sdssPrimary = 1
    ) AS crossMatch
WHERE
    distanceMins < 2/60.0
AND
    sdssType = 3

EOF




    cat > /tmp/test-query.adql << EOF
SELECT
    source_id
FROM
    (
    SELECT TOP 10
        *
    FROM
        gaia_source
    WHERE
        gaia_source.ra  BETWEEN 0 AND 1.25
    )
WHERE
    distanceMins < 2/60.0
EOF





SELECT
    ra,
    dec,
    cx,
    cy,
    cz,
    htmID




















test002 - rejected
http://redmine.roe.ac.uk/issues/442

    SELECT
        DistanceMins
    FROM
        atlasSourceXDR7PhotoObj AS crossMatch
    WHERE
        (
        SELECT
            sourceID
        FROM
            atlasSource
        WHERE
            ra BETWEEN 182 AND 184
        AND
            dec BETWEEN -1 AND -3
        AND
            crossMatch.masterOjbID = sourceID
        ) > 0






# -----------------------------------------------------
# Follow the Firethorn logs.
#[user@desktop]

    instance=vaivee1i
    composit=${HOME:?}/compose

    docker-compose \
        --file "${composit:?}/testing.yml" \
        --project ${instance:?} \
        exec \
            gillian \
            tail -f logs/firethorn.log


# -----------------------------------------------------
# Follow the OGSA-DAI logs.
#[user@desktop]

    instance=vaivee1i
    composit=${HOME:?}/compose

    docker-compose \
        --file "${composit:?}/testing.yml" \
        --project ${instance:?} \
        exec \
            jarmila \
            tail -f logs/ogsadai.log

