#
# <meta:header>
#   <meta:licence>
#     Copyright (c) 2018, ROE (http://www.roe.ac.uk/)
#
#     This information is free software: you can redistribute it and/or modify
#     it under the terms of the GNU General Public License as published by
#     the Free Software Foundation, either version 3 of the License, or
#     (at your option) any later version.
#
#     This information is distributed in the hope that it will be useful,
#     but WITHOUT ANY WARRANTY; without even the implied warranty of
#     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#     GNU General Public License for more details.
#
#     You should have received a copy of the GNU General Public License
#     along with this program.  If not, see <http://www.gnu.org/licenses/>.
#   </meta:licence>
# </meta:header>
#
#

    #
    # We have added the first ChaosMonkey code.
    # Need to find a way of triggering it ...


# -----------------------------------------------------
# Standard Python test ...
#[user@virtual]

import os
import time
import firethorn as ftpy

#
# Create our firethorn client (using named param).
firethorn = ftpy.Firethorn(
    endpoint = os.environ.get(
        'endpoint'
        )
    )

#
# Login as the admin account.
firethorn.login(
    os.environ.get('adminuser'),
    os.environ.get('adminpass'),
    os.environ.get('admingroup')
    )

#
# Create a JdbcResource to connect to the ATLAS database.
atlas_jdbc = firethorn.firethorn_engine.create_jdbc_resource(
    "ATLAS JDBC resource",
    os.environ.get('datadata'),
    '*',
    os.environ.get('datatype'),
    os.environ.get('datahost'),
    os.environ.get('datauser'),
    os.environ.get('datapass')
    )
print(
    atlas_jdbc
    )

#
# Create an AdqlResource to represent the JdbcResource.
atlas_adql = firethorn.firethorn_engine.create_adql_resource(
    "ATLAS ADQL resource"
    )
print(
    atlas_adql
    )

#
# Import the target JdbcSchema into AdqlSchema.
schema_names = [
    "ATLASDR1"
    ]

for schema_name in schema_names:
    print(schema_name)
    jdbc_schema = atlas_jdbc.select_schema_by_name(
        schema_name,
        "dbo"
        )
    if (None != jdbc_schema):
        metadoc="https://raw.githubusercontent.com/wfau/metadata/master/metadocs/" + schema_name + "_TablesSchema.xml"
        adql_schema = atlas_adql.import_jdbc_schema(
            jdbc_schema,
            schema_name,
            metadoc=metadoc
            )

#
# Admin user
# -------- -------- -------- --------
# Normal user
#

#
# Login using our guest account.
firethorn.login(
    'Hyrax',
    'frobengle23',
    os.environ.get('guestgroup')
    )

#
# Create a new workspace.
workspace = firethorn.firethorn_engine.create_adql_resource(
    "Query resource"
    )

#
# Import the ATLAS schemas into our workspace
for schema in atlas_adql.select_schemas():
    workspace.import_adql_schema(
        schema
        )

#
# Create and run a query.
query_str = "SELECT TOP 1000 ra, dec FROM ATLASDR1.atlasSource"
query_obj = workspace.create_query(
    query_str,
    "COMPLETED",
    None,
    3000000
    )
print(
    query_obj
    )

print(
    query_obj.table()
    )
print(
    query_obj.table().count()
    )

# -----------------------------------------------------
# Hack the Python code to add an extra param.
#[user@virtual]

vi /home/firethorn-py/firethorn/core/query_engine.py

    def create_query(self, ....)

        urlenc.update(
                {
                "uk.ac.roe.wfau.firethorn.ogsadai.activity.server.sql.SQLQueryActivity" : "uche2aNa"
                }
            )

    +   urlenc.update({"firethorn.monkey.name" : "uk.ac.roe.wfau.firethorn.ogsadai.activity.server.sql.SQLQueryActivity"})
    +   urlenc.update({"firethorn.monkey.data" : "uche2aNa"})

pip3 install /home/firethorn-py









