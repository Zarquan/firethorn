#
# <meta:header>
#   <meta:licence>
#     Copyright (c) 2017, ROE (http://www.roe.ac.uk/)
#
#     This information is free software: you can redistribute it and/or modify
#     it under the terms of the GNU General Public License as published by
#     the Free Software Foundation, either version 3 of the License, or
#     (at your option) any later version.
#
#     This information is distributed in the hope that it will be useful,
#     but WITHOUT ANY WARRANTY; without even the implied warranty of
#     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#     GNU General Public License for more details.
#  
#     You should have received a copy of the GNU General Public License
#     along with this program.  If not, see <http://www.gnu.org/licenses/>.
#   </meta:licence>
# </meta:header>
#
#


    Generic form

        Entity
            History
                LogEntry


        Problem with reference to the subject.
        We don't have a generic base class that covers all entities.

            @ManyToOne(
                fetch = FetchType.LAZY
                targetEntity = AbstractEntity.class
                )



    Specific form, log entries on tasks.

        BlueTask
            History
                BlueTaskLogEntry



# -----------------------------------------------------
# Remove old version of compose.
#[root@desktop]

    dnf remove docker-compose

    Removing docker-compose also removes these:

        PyYAML
        libyaml
        python-docker-py
        python-dockerpty
        python-docopt
        python-enum34
        python-jsonschema
        python-texttable
        python-websocket-client
        python2-cached_property

# -----------------------------------------------------
# Install latest version of compose.
#[root@desktop]

    curl -L https://github.com/docker/compose/releases/download/1.11.1/docker-compose-`uname -s`-`uname -m` > /usr/bin/docker-compose
    chmod +x /usr/bin/docker-compose

# -----------------------------------------------------
# Load our secret function.
#[user@desktop]

    vi ${HOME:?}/secret.sh

        ....

    source ${HOME:?}/secret.sh
    secret 'ping'

# -----------------------------------------------------
# Get the branch name and version number.
#[user@desktop]

    source "${HOME:?}/firethorn.settings"
    pushd "${FIRETHORN_CODE:?}"

        branch=$(hg branch)

        source bin/util.sh
        version=$(getversion)

    popd

# -----------------------------------------------------
# Create our chain config.
#[user@virtual] 

    cat > "${HOME:?}/chain.properties" << EOF

    branch=${branch:?}
    version=${version:?}

    buildtag=${branch:?}
    instance=$(pwgen 8 1)

    metaname=bethany
    username=patricia
    dataname=elayne
    ogsaname=jarmila
    firename=gillian
    testname=aaliyah

    metatype=pgsql
    metadata=postgres
    metauser=$(pwgen 20 1)
    metapass=$(pwgen 20 1)
    metadriver=org.postgresql.Driver

    usertype=mssql
    userhost=$(secret 'firethorn.user.host')
    userdata=$(secret 'firethorn.user.data')
    useruser=$(secret 'firethorn.user.user')
    userpass=$(secret 'firethorn.user.pass')
    userdriver=net.sourceforge.jtds.jdbc.Driver

    datatype=mssql
    datahost=$(secret 'firethorn.data.host')
    datadata=$(secret 'firethorn.data.data')
    datauser=$(secret 'firethorn.data.user')
    datapass=$(secret 'firethorn.data.pass')
    datadriver=net.sourceforge.jtds.jdbc.Driver

    tunneluser=$(secret 'ssh.tunnel.user')
    tunnelhost=$(secret 'ssh.tunnel.host')

EOF

# -----------------------------------------------------
# Generate our dockerfiles.
#[root@builder]

    source "${HOME:?}/chain.properties"
    source "${HOME:?}/firethorn.settings"
    pushd "${FIRETHORN_CODE:?}"

        source 'bin/util.sh'
        dockerfiles "${buildtag:?}"

    popd

# -----------------------------------------------------
# Remove all containers.
#[user@virtual]

    docker rm -vf $(docker ps -aq)

# -----------------------------------------------------
# Remove all images.
#[user@virtual]

    docker rmi -f $(docker images -q)

# -----------------------------------------------------
# Remove existing networks.
#[user@virtual]

    # TBD - how to only delete 'our' networks.

# -----------------------------------------------------
# Remove all volumes.
#[user@virtual]

    docker volume rm $(docker volume ls -q)

# -----------------------------------------------------
# Build our container images.
#[root@builder]

    source "${HOME:?}/chain.properties"
    source "${HOME:?}/firethorn.settings"
    pushd "${FIRETHORN_CODE:?}"

        export buildtag
        docker-compose \
            --file docker/compose/images.yml \
            build

    popd

# -----------------------------------------------------
# Create our FireThorn config.
#[user@virtual] 

    source "${HOME:?}/chain.properties"
    cat > "${HOME:?}/firethorn.properties" << EOF

firethorn.ogsadai.endpoint=http://${ogsaname:?}:8080/ogsadai/services

firethorn.meta.type=${metatype:?}
firethorn.meta.url=jdbc:postgresql://${metaname:?}/${metadata:?}
firethorn.meta.user=${metauser:?}
firethorn.meta.pass=${metapass:?}
firethorn.meta.driver=${metadriver:?}

firethorn.user.type=${usertype:?}
firethorn.user.url=jdbc:jtds:sqlserver://${username:?}/${userdata:?}
firethorn.user.user=${useruser:?}
firethorn.user.pass=${userpass:?}
firethorn.user.driver=${userdriver:?}

firethorn.ogsa.resource.scan=PT1M

EOF

    chmod a+r "${HOME:?}/firethorn.properties" 
    chcon -t svirt_sandbox_file_t "${HOME:?}/firethorn.properties" 

# -----------------------------------------------------
# Create our tester config.
#[user@virtual] 

    source "${HOME:?}/chain.properties"
    cat > "${HOME:?}/tester.properties" << EOF

        datadata=${datadata:?}
        dataname=${dataname:?}
        datauser=${datauser:?}
        datapass=${datapass:?}
        datadriver=${datadriver:?}
        endpointurl=http://${firename:?}:8080/firethorn

EOF

    chmod a+r "${HOME:?}/tester.properties" 
    chcon -t svirt_sandbox_file_t "${HOME:?}/tester.properties" 

# -----------------------------------------------------
# Create our composer env file.
#[user@desktop]

    source "${HOME:?}/chain.properties"
    source "${HOME:?}/firethorn.settings"

    cat > "${HOME:?}/.env" << EOF
buildtag=${buildtag:?}

metauser=${metauser:?}
metapass=${metapass:?}

datahost=${datahost:?}
userhost=${userhost:?}

tunneluser=${tunneluser:?}
tunnelhost=${tunnelhost:?}

EOF

#---------------------------------------------------------------------
# Build our Java components.
#[user@desktop] 

    source "${HOME:?}/chain.properties"
    source "${HOME:?}/firethorn.settings"
    pushd "${FIRETHORN_CODE:?}"

        mvn -P all clean install

    popd

# -----------------------------------------------------
# Build our Java containers.
#[user@desktop]

    source "${HOME:?}/chain.properties"
    source "${HOME:?}/firethorn.settings"
    pushd "${FIRETHORN_CODE:?}"

        export buildtag
        pushd firethorn-ogsadai/webapp
            mvn docker:package
        popd

        export buildtag
        pushd firethorn-webapp
            mvn docker:package
        popd

    popd

# -----------------------------------------------------
# Run our docker chain.
#[user@desktop]

    source "${HOME:?}/chain.properties"
    source "${HOME:?}/firethorn.settings"

    composit=${FIRETHORN_CODE:?}/docker/compose/testing.yml

    docker-compose \
        --file "${composit:?}" \
        --project ${instance:?} \
        up -d gillian

# -----------------------------------------------------
# Run our tester.
#[user@desktop]

    docker-compose \
        --file "${composit:?}" \
        --project ${instance:?} \
        run tester 








# -----------------------------------------------------
# Load our configuration.
#[root@tester]

        source /etc/tester.properties

# -----------------------------------------------------
# Configure our identity.
#[root@tester]

        identity=${identity:-$(date '+%H:%M:%S')}
        community=${community:-$(date '+%A %-d %B %Y')}

        source "bin/01-01-init-rest.sh"

# -----------------------------------------------------
# Check the system info.
#[root@tester]

        curl \
            --silent \
            --header "firethorn.auth.identity:${identity:?}" \
            --header "firethorn.auth.community:${community:?}" \
            "${endpointurl:?}/system/info" \
            | bin/pp | tee /tmp/system-info.json

# -----------------------------------------------------
# Load the local TWOMASS resource.
#[root@tester]

        source "bin/02-02-create-jdbc-space.sh" \
            'TWOMASS JDBC conection' \
            "jdbc:jtds:sqlserver://${dataname:?}/TWOMASS" \
            "${datauser:?}" \
            "${datapass:?}" \
            "${datadriver:?}" \
            '*'
        wfaujdbc=${jdbcspace:?}

        source "bin/03-01-create-adql-space.sh" 'TWOMASS ADQL workspace'
        wfauadql=${adqlspace:?}

        source "bin/03-04-import-jdbc-metadoc.sh" "${wfaujdbc:?}" "${wfauadql:?}" 'TWOMASS' 'dbo' "meta/TWOMASS_TablesSchema.xml"

# -----------------------------------------------------
# Create a workspace and add the local TWOMASS schema.
#[root@tester]

        source "bin/04-01-create-query-space.sh"  'Test workspace'
        source "bin/04-03-import-query-schema.sh" "${wfauadql:?}" 'TWOMASS' 'wfau'

# -----------------------------------------------------
# Test queries ...
#[root@tester]

        curl \
            --silent \
            --header "firethorn.auth.identity:${identity:?}" \
            --header "firethorn.auth.community:${community:?}" \
            --data "adql.query.input=SELECT TOP 2000 designation, ra, dec FROM wfau.twomass_psc WHERE (ra BETWEEN 0 AND 0.5) AND (dec BETWEEN 0 AND 0.5)" \
            --data "adql.query.status.next=COMPLETED" \
            --data "adql.query.wait.time=600000" \
            "${endpointurl:?}/${queryspace:?}/queries/create" \
            | bin/pp | tee /tmp/wfau-query.json

        #
        # Get URL for the results as VOTable
        wfaudata=$(cat /tmp/wfau-query.json | votable)

        #
        # Get the results as VOTable files
        curl --silent "${wfaudata:?}" | xmlstarlet fo | tee /tmp/wfau-data.xml

        #
        # Remove XML namespaces
        sed -i 's#<VOTABLE[^>]*>#<VOTABLE>#' /tmp/wfau-data.xml

        #
        # Select a specific row.
        xmlstarlet sel -t -c "//TR[TD='00012764+0028492']" /tmp/wfau-data.xml | xmlstarlet fo





# -----------------------------------------------------
# Create the GAVO TWOMASS resource.
#[root@tester]

        #
        # Create the IvoaResource
        source "bin/02-03-create-ivoa-space.sh" \
            'GAVO TAP service' \
            'http://dc.zah.uni-heidelberg.de/__system__/tap/run/tap'
        gavoivoa=${ivoaspace:?}

        #
        # Import the static VOSI file
        vosifile='vosi/gavo/gavo-tableset.xml'
        curl \
            --header "firethorn.auth.identity:${identity:?}" \
            --header "firethorn.auth.community:${community:?}" \
            --form   "vosi.tableset=@${vosifile:?}" \
            "${endpointurl:?}/${gavoivoa:?}/vosi/import" \
            | bin/pp

        #
        # Find the Gavo twomass schema
        findname=twomass
        curl \
            --header "firethorn.auth.identity:${identity:?}" \
            --header "firethorn.auth.community:${community:?}" \
            --data   "ivoa.resource.schema.name=${findname:?}" \
            "${endpointurl:?}/${gavoivoa:?}/schemas/select" \
            | bin/pp | tee /tmp/gavo-schema.json

        gavoschema=$(
            cat /tmp/gavo-schema.json | self
            )

# --------------------------------------
# Create the GAIA TAP resource.
#[root@tester]

        #
        # Create the IvoaResource
        source "bin/02-03-create-ivoa-space.sh" \
            'GAIA TAP service' \
            'http://gea.esac.esa.int/tap-server/tap'
        gaiaivoa=${ivoaspace:?}

        #
        # Import the static VOSI file
        vosifile='vosi/gaia/gaia-tableset.xml'
        curl \
            --header "firethorn.auth.identity:${identity:?}" \
            --header "firethorn.auth.community:${community:?}" \
            --form   "vosi.tableset=@${vosifile:?}" \
            "${endpointurl:?}/${gaiaivoa:?}/vosi/import" \
            | bin/pp

        #
        # Find the Gaia DR1 schema
        findname=gaiadr1
        curl \
            --header "firethorn.auth.identity:${identity:?}" \
            --header "firethorn.auth.community:${community:?}" \
            --data   "ivoa.resource.schema.name=${findname:?}" \
            "${endpointurl:?}/${gaiaivoa:?}/schemas/select" \
            | bin/pp | tee /tmp/gaia-schema.json

        gaiaschema=$(
            cat /tmp/gaia-schema.json | self
            )

# -----------------------------------------------------
# Add the GAVO TWOMASS schema to our workspace.
#[root@tester]

        gavoname=gavo
        curl \
            --header "firethorn.auth.identity:${identity:?}" \
            --header "firethorn.auth.community:${community:?}" \
            --data   "urn:adql.copy.depth=${adqlcopydepth:-THIN}" \
            --data   "adql.resource.schema.import.name=${gavoname:?}" \
            --data   "adql.resource.schema.import.base=${gavoschema:?}" \
            "${endpointurl:?}/${queryspace:?}/schemas/import" \
            | bin/pp | tee /tmp/query-schema.json

# -----------------------------------------------------
# Add the Gaia DR1 schema to our workspace.
#[root@tester]

        gaianame=gaia
        curl \
            --header "firethorn.auth.identity:${identity:?}" \
            --header "firethorn.auth.community:${community:?}" \
            --data   "urn:adql.copy.depth=${adqlcopydepth:-THIN}" \
            --data   "adql.resource.schema.import.name=${gaianame:?}" \
            --data   "adql.resource.schema.import.base=${gaiaschema:?}" \
            "${endpointurl:?}/${queryspace:?}/schemas/import" \
            | bin/pp | tee /tmp/query-schema.json

# -----------------------------------------------------
# Test queries ...
#[root@tester]

        curl \
            --silent \
            --header "firethorn.auth.identity:${identity:?}" \
            --header "firethorn.auth.community:${community:?}" \
            --data "adql.query.input=SELECT TOP 2000 designation, ra, dec FROM wfau.twomass_psc WHERE (ra BETWEEN 0 AND 0.5) AND (dec BETWEEN 0 AND 0.5)" \
            --data "adql.query.status.next=COMPLETED" \
            --data "adql.query.wait.time=600000" \
            "${endpointurl:?}/${queryspace:?}/queries/create" \
            | bin/pp | tee /tmp/wfau-query.json

        curl \
            --silent \
            --header "firethorn.auth.identity:${identity:?}" \
            --header "firethorn.auth.community:${community:?}" \
            --data "adql.query.input=SELECT TOP 2000 mainid AS designation, raj2000 AS ra, dej2000 AS dec FROM gavo.data WHERE (raj2000 BETWEEN 0 AND 0.5) AND (dej2000 BETWEEN 0 AND 0.5)" \" \
            --data "adql.query.status.next=COMPLETED" \
            --data "adql.query.wait.time=600000" \
            "${endpointurl:?}/${queryspace:?}/queries/create" \
            | bin/pp | tee /tmp/gavo-query.json

        curl \
            --silent \
            --header "firethorn.auth.identity:${identity:?}" \
            --header "firethorn.auth.community:${community:?}" \
            --data "adql.query.input=SELECT TOP 2000 designation, ra, dec  FROM gaia.tmass_original_valid WHERE (ra BETWEEN 0 AND 0.5) AND (dec BETWEEN 0 AND 0.5)" \
            --data "adql.query.status.next=COMPLETED" \
            --data "adql.query.wait.time=600000" \
            "${endpointurl:?}/${queryspace:?}/queries/create" \
            | bin/pp | tee /tmp/gaia-query.json

        #
        # Get URLs for the results as VOTable
        wfaudata=$(cat /tmp/wfau-query.json | votable)
        gavodata=$(cat /tmp/gavo-query.json | votable)
        gaiadata=$(cat /tmp/gaia-query.json | votable)

        #
        # Get the results as VOTable files
        curl --silent "${wfaudata:?}" | xmlstarlet fo > /tmp/wfau-data.xml
        curl --silent "${gavodata:?}" | xmlstarlet fo > /tmp/gavo-data.xml
        curl --silent "${gaiadata:?}" | xmlstarlet fo > /tmp/gaia-data.xml

        #
        # Remove XML namespaces
        sed -i 's#<VOTABLE[^>]*>#<VOTABLE>#' /tmp/wfau-data.xml
        sed -i 's#<VOTABLE[^>]*>#<VOTABLE>#' /tmp/gavo-data.xml
        sed -i 's#<VOTABLE[^>]*>#<VOTABLE>#' /tmp/gaia-data.xml

        #
        # Select a specific row.
        xmlstarlet sel -t -c "//TR[TD='00012764+0028492']" /tmp/wfau-data.xml | xmlstarlet fo
        xmlstarlet sel -t -c "//TR[TD='00012764+0028492']" /tmp/gavo-data.xml | xmlstarlet fo
        xmlstarlet sel -t -c "//TR[TD='00012764+0028492']" /tmp/gaia-data.xml | xmlstarlet fo

# -----------------------------------------------------
# Create our join query ...
#[root@tester]

    cat > /tmp/join-query.adql << EOF

    SELECT
        gaia.tmass_best_neighbour.original_ext_source_id AS gaia_ident,
        wfau.twomass_psc.designation                     AS wfau_ident,

        gaia.tmass_best_neighbour.source_id              AS best_source_id,
        gaia.gaia_source.source_id                       AS gaia_source_id,

        wfau.twomass_psc.ra                              AS wfau_ra,
        gaia.gaia_source.ra                              AS gaia_ra,

        wfau.twomass_psc.ra - gaia.gaia_source.ra        AS delta_ra,

        wfau.twomass_psc.dec                             AS wfau_dec,
        gaia.gaia_source.dec                             AS gaia_dec,

        wfau.twomass_psc.dec - gaia.gaia_source.dec      AS delta_dec

    FROM
        gaia.gaia_source,
        gaia.tmass_best_neighbour,
        wfau.twomass_psc

    WHERE
        gaia.tmass_best_neighbour.source_id = gaia.gaia_source.source_id
    AND
        gaia.tmass_best_neighbour.original_ext_source_id = wfau.twomass_psc.designation
    AND
        gaia.gaia_source.ra  BETWEEN 0 AND 1.25
    AND
        gaia.gaia_source.dec BETWEEN 0 AND 1.25
    AND
        wfau.twomass_psc.ra  BETWEEN 0 AND 1.25
    AND
        wfau.twomass_psc.dec BETWEEN 0 AND 1.25

EOF

# -----------------------------------------------------
# Execute our join query.
#[root@tester]

        curl \
            --silent \
            --header "firethorn.auth.identity:${identity:?}" \
            --header "firethorn.auth.community:${community:?}" \
            --data-urlencode "adql.query.input@/tmp/join-query.adql" \
            --data "adql.query.status.next=COMPLETED" \
            --data "adql.query.wait.time=600000" \
            "${endpointurl:?}/${queryspace:?}/queries/create" \
            | bin/pp | tee /tmp/join-query.json

        #
        # Get the URL for the results as VOTable
        joindata=$(cat /tmp/join-query.json | votable)

        #
        # Get the results as VOTable
        curl --silent "${joindata:?}" | xmlstarlet fo > /tmp/join-data.xml

        #
        # Remove XML namespaces
        sed -i 's#<VOTABLE[^>]*>#<VOTABLE>#' /tmp/join-data.xml

        #
        # Select a specific row.
        xmlstarlet sel -t -c "//TR[TD='00012764+0028492']" /tmp/join-data.xml | xmlstarlet fo






















# -----------------------------------------------------
# Remove our docker chain.
#[user@desktop]

    source "${HOME:?}/chain.properties"
    source "${HOME:?}/firethorn.settings"
    composit=${FIRETHORN_CODE:?}/docker/compose/testing.yml

    docker-compose \
        --file "${composit:?}" \
        --project ${instance:?} \
        down --volumes

#---------------------------------------------------------------------
# Rebuild our Firethorn container.
#[user@desktop] 

    source "${HOME:?}/chain.properties"
    source "${HOME:?}/firethorn.settings"
    pushd "${FIRETHORN_CODE:?}"

        mvn -P all clean install

        export buildtag
        pushd firethorn-webapp
            mvn docker:package
        popd

    popd

# -----------------------------------------------------
# Run our docker chain.
#[user@desktop]

    source "${HOME:?}/chain.properties"
    source "${HOME:?}/firethorn.settings"
    composit=${FIRETHORN_CODE:?}/docker/compose/testing.yml

    docker-compose \
        --file "${composit:?}" \
        --project ${instance:?} \
        up -d gillian

# -----------------------------------------------------
# List our containers.
#[user@desktop]

    source "${HOME:?}/chain.properties"
    source "${HOME:?}/firethorn.settings"
    composit=${FIRETHORN_CODE:?}/docker/compose/testing.yml

    docker-compose \
        --file "${composit:?}" \
        --project ${instance:?} \
        ps
        
# -----------------------------------------------------
# Follow the container logs.
#[user@desktop]

    source "${HOME:?}/chain.properties"
    source "${HOME:?}/firethorn.settings"
    composit=${FIRETHORN_CODE:?}/docker/compose/testing.yml

    docker-compose \
        --file "${composit:?}" \
        --project ${instance:?} \
        logs \
            --timestamps \
            --follow

# -----------------------------------------------------
# Follow the container events.
#[user@desktop]

    source "${HOME:?}/chain.properties"
    source "${HOME:?}/firethorn.settings"
    composit=${FIRETHORN_CODE:?}/docker/compose/testing.yml

    docker-compose \
        --file "${composit:?}" \
        --project ${instance:?} \
        events \
            --json

# -----------------------------------------------------
# Follow the Firethorn logs.
#[user@desktop]

    source "${HOME:?}/chain.properties"
    source "${HOME:?}/firethorn.settings"
    composit=${FIRETHORN_CODE:?}/docker/compose/testing.yml

    docker-compose \
        --file "${composit:?}" \
        --project ${instance:?} \
        exec \
            gillian \
            tail -f logs/firethorn.log


# -----------------------------------------------------
# Follow the OGSA-DAI logs.
#[user@desktop]

    source "${HOME:?}/chain.properties"
    source "${HOME:?}/firethorn.settings"
    composit=${FIRETHORN_CODE:?}/docker/compose/testing.yml

    docker-compose \
        --file "${composit:?}" \
        --project ${instance:?} \
        exec \
            jarmila \
            tail -f logs/ogsadai.log



