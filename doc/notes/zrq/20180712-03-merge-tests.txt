#
# <meta:header>
#   <meta:licence>
#     Copyright (c) 2018, ROE (http://www.roe.ac.uk/)
#
#     This information is free software: you can redistribute it and/or modify
#     it under the terms of the GNU General Public License as published by
#     the Free Software Foundation, either version 3 of the License, or
#     (at your option) any later version.
#
#     This information is distributed in the hope that it will be useful,
#     but WITHOUT ANY WARRANTY; without even the implied warranty of
#     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#     GNU General Public License for more details.
#  
#     You should have received a copy of the GNU General Public License
#     along with this program.  If not, see <http://www.gnu.org/licenses/>.
#   </meta:licence>
# </meta:header>
#
#

# -----------------------------------------------------
# Create our chain properties.
#[user@builder]

    cat > "${FIRETHORN_HOME:?}/chain.properties" << EOF

        metadata=$(pwgen 20 1)
        metauser=$(pwgen 20 1)
        metapass=$(pwgen 20 1)

        usertype=mssql
        userhost=$(secret 'firethorn.user.host')
        userdata=$(secret 'firethorn.user.data')
        useruser=$(secret 'firethorn.user.user')
        userpass=$(secret 'firethorn.user.pass')

        datatype=mssql
        datahost=$(secret 'firethorn.data.host')
        datadata=$(secret 'firethorn.data.data')
        datauser=$(secret 'firethorn.data.user')
        datapass=$(secret 'firethorn.data.pass')

        tunneluser=$(secret 'ssh.tunnel.user')
        tunnelhost=$(secret 'ssh.tunnel.host')

        admingroup=Hyaenidae
        adminuser=Aardwolf
        adminpass=$(pwgen 20 1)

        guestgroup=Afrotheria
        guestuser=Hyrax
        guestpass=$(pwgen 20 1)

        tapresource=Wilhelmina
        tapschemadata=data-$(pwgen 10 1)
        tapschemauser=user-$(pwgen 10 1)
        tapschemapass=pass-$(pwgen 10 1)

EOF

# -----------------------------------------------------
# Link our compose config.
#[user@builder]

    ln -sf "${FIRETHORN_HOME:?}/chain.properties" "${FIRETHORN_HOME:?}/.env"

# -----------------------------------------------------
# Start our test containers ...
#[user@builder]
    
    pushd "${FIRETHORN_HOME:?}"

    docker-compose \
        --file "${FIRETHORN_CODE:?}/docker/compose/tests/baryptera/baryptera-local.yml" \
        run \
            angela
   
# -----------------------------------------------------
# Run our Python tests ...
#[user@python]

import os
import uuid
import time
import firethorn as ftpy

#
# Create our firethorn client (using named param).
firethorn = ftpy.Firethorn(
    endpoint = os.environ.get(
        'endpoint'
        )
    )

#
# Login as the admin account.
firethorn.login(
    os.environ.get('adminuser'),
    os.environ.get('adminpass'),
    os.environ.get('admingroup')
    )

#
# Create a JdbcResource to connect to the ATLAS database.
atlas_jdbc = firethorn.firethorn_engine.create_jdbc_resource(
    "ATLAS JDBC resource",
    os.environ.get('datadata'),
    '*',
    os.environ.get('datatype'),
    os.environ.get('datahost'),
    os.environ.get('datauser'),
    os.environ.get('datapass')
    )
print(
    atlas_jdbc
    )

#
# Create an AdqlResource to represent the JdbcResource.
atlas_adql = firethorn.firethorn_engine.create_adql_resource(
    "ATLAS ADQL resource"
    )
print(
    atlas_adql
    )

#
# Import the target JdbcSchema into AdqlSchema.
schema_names = [
    "ATLASDR1"
    ]

for schema_name in schema_names:
    print(schema_name)
    jdbc_schema = atlas_jdbc.select_schema_by_name(
        schema_name,
        "dbo"
        )
    if (None != jdbc_schema):
        metadoc="https://raw.githubusercontent.com/wfau/metadata/master/metadocs/" + schema_name + "_TablesSchema.xml"
        adql_schema = atlas_adql.import_jdbc_schema(
            jdbc_schema,
            schema_name,
            metadoc=metadoc
            )

#
# Admin user
# -------- -------- -------- --------
# Normal user
#

#
# Login using a guest account.
firethorn.login(
    str(uuid.uuid4()),
    str(uuid.uuid4()),
    None
    )

#
# Create a new workspace.
workspace = firethorn.firethorn_engine.create_adql_resource(
    "Query resource"
    )

#
# Import the ATLAS schemas into our workspace
for schema in atlas_adql.select_schemas():
    workspace.import_adql_schema(
        schema
        )

#
# Create and run a query.
query_str = "SELECT TOP 1000 ra, dec FROM ATLASDR1.atlasSource"
query_obj = workspace.create_query(
    query_str,
    "COMPLETED",
    None,
    3000000
    )
print(
    query_obj
    )
print(
    query_obj.table()
    )
print(
    query_obj.table().count()
    )

#
# Iterate the metadata tree
for schema in atlas_adql.select_schemas():
    for table in schema.select_tables():
        print(
            "table  [{}][{}]".format(
                schema.name(),
                table.name()
                )
            )
        query_str = "SELECT TOP 10 * FROM {}.{}".format(
            schema.name(),
            table.name()
            )
        query_obj = workspace.create_query(
            query_str,
            "COMPLETED",
            None,
            3000000
            )
        py_table = query_obj.table().as_astropy()
        py_table.pprint()

#
# Run some queries in parallel
from concurrent.futures import ThreadPoolExecutor
import concurrent.futures

query_str = "SELECT TOP 10000 ra, dec FROM ATLASDR1.atlasSource"

def do_query(workspace, query_str, limit, delay):
    query_obj = workspace.create_query(
        query_str,
        "COMPLETED",
        None,
        200000,
            {
            "adql.query.limit.rows"  : limit,
            "adql.query.delay.every" : delay
            }
        )
    return query_obj.json_object.get("results").get("count")

def do_queries(workspace, query_str, threads, delay):
    with concurrent.futures.ThreadPoolExecutor(threads) as executor:
        futures = {
            executor.submit(
                do_query,
                workspace,
                query_str,
                limit,
                delay
                ): limit for limit in range(threads, 0, -1)
            }
        for future in concurrent.futures.as_completed(futures):
            print(
                future.result()
                )

for threads in range(1, 20):
    for delay in range(500, -100, -100):
        print("---- ", threads, delay)
        do_queries(
            workspace,
            query_str,
            threads,
            delay
            )


#
# Exit the Python shell

    Ctrl^D
    
# -----------------------------------------------------
# Shutdown our containers ...
#[user@virtual]

    docker-compose \
        --file "${FIRETHORN_CODE:?}/docker/compose/tests/baryptera/baryptera-local.yml" \
        down

# -----------------------------------------------------
# Separate shell on the host VM, locate the logs volume.
#[user@virtual]

    sudo -s

    container=baryptera_gillian_1
    
    pushd $(
        docker inspect \
            "${container:?}" \
      | jq -r '
            .[].Mounts | .[] | select(.Destination == "/var/local/tomcat/logs") | .Source
            '
            )

    tail -f firethorn-debug.log


