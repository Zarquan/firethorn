#
# <meta:header>
#   <meta:licence>
#     Copyright (c) 2015, ROE (http://www.roe.ac.uk/)
#
#     This information is free software: you can redistribute it and/or modify
#     it under the terms of the GNU General Public License as published by
#     the Free Software Foundation, either version 3 of the License, or
#     (at your option) any later version.
#
#     This information is distributed in the hope that it will be useful,
#     but WITHOUT ANY WARRANTY; without even the implied warranty of
#     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#     GNU General Public License for more details.
#  
#     You should have received a copy of the GNU General Public License
#     along with this program.  If not, see <http://www.gnu.org/licenses/>.
#   </meta:licence>
# </meta:header>
#
#

    #
    # Configure and run a simple test, using standard containers.
    #

# -----------------------------------------
# Create a new virtual machine
#[user@shep]

    createvm

        ....
        ....
        
        INFO : Node name [badari]
        INFO : Base name [fedora-21-16G-20150407.qcow]
        INFO : Base path [/home/dave/projects/libvirt/base/fedora-21-16G-20150407.qcow]
        INFO : Disc name [badari.qcow]
        INFO : Disc size [16GiB]

# -----------------------------------------
# Update the local SSH fingerprint.
# TODO automate the IP address selection.
#[user@shep]

    # http://linux.die.net/man/1/ssh-keygen
    # http://linux.die.net/man/1/ssh-keyscan

    ssh-keygen -f "${HOME:?}/.ssh/known_hosts" -R "192.168.122.11"

# -----------------------------------------
# Login to the new virtual machine
#[user@shep]

    ssh badari

# -----------------------------------------
# Install missing tools.
#[root@virtual]

    yum -y install htop
    yum -y install pwgen
    
# -----------------------------------------------------
# Install and start the HAVEGE entropy generator.
# http://redmine.roe.ac.uk/issues/828
# http://blog-ftweedal.rhcloud.com/2014/05/more-entropy-with-haveged/
# http://stackoverflow.com/questions/26021181/not-enough-entropy-to-support-dev-random-in-docker-containers-running-in-boot2d/
#[root@edfu]

    yum install -y haveged
    systemctl start haveged.service

# -----------------------------------------------------
# Install and run Docker.
#[root@virtual]

    yum -y install docker-io

    systemctl enable docker.service
    systemctl start  docker.service
    systemctl status docker.service

# -----------------------------------------------------
# Configure our chain.
#[root@virtual]

    version=1.13.10

    metaname=bethany
    username=patricia
    dataname=elayne
    ogsaname=jarmila
    firename=gillian

    metalink=albert
    userlink=edward
    datalink=sebastien
    ogsalink=timothy
    firelink=peter

    metadata=postgres
    metauser=$(pwgen 20 1)
    metapass=$(pwgen 20 1)

    userhost=ramses2
    userdata=xxxx-xxxx-xxxx
    useruser=xxxx-xxxx-xxxx
    userpass=xxxx-xxxx-xxxx

    datahost=ramses2
    datauser=xxxx-xxxx-xxxx
    datapass=xxxx-xxxx-xxxx
    datadriver=net.sourceforge.jtds.jdbc.Driver

# -----------------------------------------------------
# Run our userdata ambassador.
#[root@virtual]

    docker run \
        --detach \
        --name "${username:?}" \
        --env  "target=${userhost:?}" \
        firethorn/sql-proxy:1

# -----------------------------------------------------
# Run our science data ambassador.
#[root@virtual]

    docker run \
        --detach \
        --name "${dataname:?}" \
        --env  "target=${datahost:?}" \
        firethorn/sql-proxy:1

# -----------------------------------------------------
# Run our PostgreSQL metadata container.
#[root@virtual]

    docker run \
        --detach \
        --name "${metaname:?}" \
        --env "POSTGRES_USER=${metauser:?}" \
        --env "POSTGRES_PASSWORD=${metapass:?}" \
        postgres

# -----------------------------------------------------
# Run our OGSA-DAI container.
#[root@virtual]

    docker run \
        --detach \
        --publish 8081:8080 \
        --name "${ogsaname:?}" \
        --link "${dataname:?}:${datalink:?}" \
        --link "${username:?}:${userlink:?}" \
        "firethorn/ogsadai:${version:?}"

# -----------------------------------------------------
# Create our FireThorn config.
#[root@virtual]

    properties=$(mktemp)
    cat > "${properties:?}" << EOF

firethorn.ogsadai.endpoint=http://${ogsalink:?}:8080/ogsadai/services

firethorn.meta.url=jdbc:postgresql://${metalink:?}/${metadata:?}
firethorn.meta.user=${metauser:?}
firethorn.meta.pass=${metapass:?}
firethorn.meta.driver=org.postgresql.Driver

firethorn.user.url=jdbc:jtds:sqlserver://${userlink:?}/${userdata:?}
firethorn.user.user=${useruser:?}
firethorn.user.pass=${userpass:?}
firethorn.user.driver=net.sourceforge.jtds.jdbc.Driver
firethorn.user.type=mssql

EOF

    chmod a+r "${properties:?}" 
    chcon -t svirt_sandbox_file_t "${properties:?}" 

# -----------------------------------------------------
# Run our FireThorn container.
#[root@virtual]

    docker run \
        --detach \
        --publish 8080:8080 \
        --name "${firename:?}" \
        --link "${ogsaname:?}:${ogsalink:?}" \
        --link "${metaname:?}:${metalink:?}" \
        --link "${dataname:?}:${datalink:?}" \
        --link "${username:?}:${userlink:?}" \
        --volume "${properties:?}:/etc/firethorn.properties" \
        "firethorn/firethorn:${version:?}"

# -----------------------------------------------------
# Run our test container.
#[root@virtual]

    docker run \
        --rm --tty \
        --interactive \
        --env "datalink=${datalink:?}" \
        --env "datauser=${datauser:?}" \
        --env "datapass=${datapass:?}" \
        --env "datadriver=${datadriver:?}" \
        --env "endpointurl=http://${firelink:?}:8080/firethorn" \
        --link "${firename:?}:${firelink:?}" \
        "firethorn/tester:${version:?}" \
        bash

# -----------------------------------------------------
# Configure our identity.
#[root@tester]

        identity=${identity:-$(date '+%H:%M:%S')}
        community=${community:-$(date '+%A %-d %B %Y')}

        source "bin/01-01-init-rest.sh"

# -----------------------------------------------------
# Load the Atlas resource.
#[root@tester]

        database=ATLASDR1

        source "bin/02-02-create-jdbc-space.sh" \
            'Atlas JDBC conection' \
            "jdbc:jtds:sqlserver://${datalink:?}/${database:?}" \
            "${datauser:?}" \
            "${datapass:?}" \
            "${datadriver:?}" \
            '*'
        atlasjdbc=${jdbcspace:?}

        source "bin/03-01-create-adql-space.sh" 'Atlas ADQL workspace'
        atlasadql=${adqlspace:?}

        source "bin/03-04-import-jdbc-metadoc.sh" "${atlasjdbc:?}" "${atlasadql:?}" 'ATLASDR1' 'dbo' "meta/ATLASDR1_AtlasSource.xml"
        atlasschema=${adqlschema:?}

        source "bin/03-04-import-jdbc-metadoc.sh" "${atlasjdbc:?}" "${atlasadql:?}" 'ATLASDR1' 'dbo' "meta/ATLASDR1_AtlasTwomass.xml"
        atlascross=${adqlschema:?}

        source "bin/03-04-import-jdbc-metadoc.sh" "${atlasjdbc:?}" "${atlasadql:?}" 'TWOMASS'  'dbo' "meta/TWOMASS_TwomassPsc.xml"
        atlastwomass=${adqlschema:?}

# -----------------------------------------------------
# Run our ATLASDR1 queries
#[root@tester]

        source "bin/04-01-create-query-space.sh" 'Test workspace'

        source "bin/04-03-import-query-schema.sh" "${atlasadql:?}" 'ATLASDR1' 'atlas'
        source "bin/04-03-import-query-schema.sh" "${atlasadql:?}" 'TWOMASS'  'twomass'

        source "bin/04-03-create-query-schema.sh"

        source "bin/05-03-execute-query.sh" \
            "AUTO" \
            "
            SELECT
                atlasSource.ra,
                atlasSource.dec
            FROM
                atlas.atlasSource
            WHERE
                atlasSource.ra  BETWEEN 354 AND 355
            AND
                atlasSource.dec BETWEEN -40 AND -39
            "

        source "bin/05-03-execute-query.sh" \
            "AUTO" \
            "
            SELECT
                twomass_psc.ra,
                twomass_psc.dec
            FROM
                twomass.twomass_psc
            WHERE
                twomass_psc.ra  BETWEEN 354 AND 355
            AND
                twomass_psc.dec BETWEEN -40 AND -39
            "

        source "bin/05-03-execute-query.sh" \
            "AUTO" \
            "
            SELECT
                atlasSource.ra  as atlasra,
                atlasSource.dec as atlasdec,
                twomass_psc.ra  as twomassra,
                twomass_psc.dec as twomassdec
            FROM
                atlasSource
            JOIN
                atlasSourceXtwomass_psc
            ON
                atlasSource.sourceID = atlasSourceXtwomass_psc.masterObjID 
            JOIN
                twomass_psc
            ON
                twomass_psc.pts_key = atlasSourceXtwomass_psc.slaveObjID
            WHERE
                atlasSource.ra  BETWEEN 354 AND 355
            AND
                atlasSource.dec BETWEEN -40 AND -39
            AND
                twomass_psc.ra  BETWEEN 354 AND 355
            AND
                twomass_psc.dec BETWEEN -40 AND -39
            "

# -----------------------------------------------------
# Load the TWOMASS resource.
#[root@tester]

        database=TWOMASS

        source "bin/02-02-create-jdbc-space.sh" \
            'TWOMASS JDBC conection' \
            "jdbc:jtds:sqlserver://${datalink:?}/${database:?}" \
            "${datauser:?}" \
            "${datapass:?}" \
            "${datadriver:?}" \
            "${database:?}"
        twomassjdbc=${jdbcspace:?}

        source "bin/03-01-create-adql-space.sh" 'TWOMASS ADQL workspace'
        twomassadql=${adqlspace:?}

        source "bin/03-04-import-jdbc-metadoc.sh" "${twomassjdbc:?}" "${twomassadql:?}" 'TWOMASS'  'dbo' "meta/TWOMASS_TwomassPsc.xml"
        twomassschema=${adqlschema:?}

# -----------------------------------------------------
# Run our ATLASDR1/TWOMASS queries
#[root@tester]

        source "bin/04-01-create-query-space.sh" 'Test workspace'

        source "bin/04-03-import-query-schema.sh" "${atlasadql:?}"   'ATLASDR1' 'atlas'
        source "bin/04-03-import-query-schema.sh" "${twomassadql:?}" 'TWOMASS'  'twomass'

        source "bin/04-03-create-query-schema.sh"

        source "bin/05-03-execute-query.sh" \
            "AUTO" \
            "
            SELECT
                atlasSource.ra,
                atlasSource.dec
            FROM
                atlas.atlasSource
            WHERE
                atlasSource.ra  BETWEEN 354 AND 355
            AND
                atlasSource.dec BETWEEN -40 AND -39
            "

        source "bin/05-03-execute-query.sh" \
            "AUTO" \
            "
            SELECT
                twomass_psc.ra,
                twomass_psc.dec
            FROM
                twomass.twomass_psc
            WHERE
                twomass_psc.ra  BETWEEN 354 AND 355
            AND
                twomass_psc.dec BETWEEN -40 AND -39
            "

        source "bin/05-03-execute-query.sh" \
            "AUTO" \
            "
            SELECT
                atlasSource.ra  as atra,
                atlasSource.dec as atdec,
                twomass_psc.ra  as tmra,
                twomass_psc.dec as tmdec,
                atlasSourceXtwomass_psc.distanceMins as dist
            FROM
                atlasSource
            JOIN
                atlasSourceXtwomass_psc
            ON
                atlasSource.sourceID = atlasSourceXtwomass_psc.masterObjID 
            JOIN
                twomass_psc
            ON
                twomass_psc.pts_key = atlasSourceXtwomass_psc.slaveObjID
            WHERE
                atlasSource.ra  BETWEEN 354 AND 355
            AND
                atlasSource.dec BETWEEN -40 AND -39
            AND
                twomass_psc.ra  BETWEEN 354 AND 355
            AND
                twomass_psc.dec BETWEEN -40 AND -39
            "

# -----------------------------------------------------
# Unbounded tes queries
#[root@tester]


        #
        # This works, and is fairly fast.
        source "bin/05-03-execute-query.sh" \
            "AUTO" \
            "
            SELECT
                atlasSource.ra  as atra,
                atlasSource.dec as atdec,
                twomass_psc.ra  as tmra,
                twomass_psc.dec as tmdec,
                atlasSourceXtwomass_psc.distanceMins as dist
            FROM
                atlasSource
            JOIN
                atlasSourceXtwomass_psc
            ON
                atlasSource.sourceID = atlasSourceXtwomass_psc.masterObjID 
            JOIN
                twomass_psc
            ON
                twomass_psc.pts_key = atlasSourceXtwomass_psc.slaveObjID
            WHERE
                twomass_psc.ra  BETWEEN 354 AND 355
            AND
                twomass_psc.dec BETWEEN -40 AND -39
            "

        #
        # This, I have yet to see complete (> 12hrs).
        # It uses string concatenation to send lots of
        # "WHERE xxx IN (xxx, yyy, zzz)"
        # queries to the remote system.
        source "bin/05-03-execute-query.sh" \
            "AUTO" \
            "
            SELECT
                atlasSource.ra  as atra,
                atlasSource.dec as atdec,
                twomass_psc.ra  as tmra,
                twomass_psc.dec as tmdec,
                atlasSourceXtwomass_psc.distanceMins as dist
            FROM
                atlasSource
            JOIN
                atlasSourceXtwomass_psc
            ON
                atlasSource.sourceID = atlasSourceXtwomass_psc.masterObjID 
            JOIN
                twomass_psc
            ON
                twomass_psc.pts_key = atlasSourceXtwomass_psc.slaveObjID
            WHERE
                atlasSource.ra  BETWEEN 354 AND 355
            AND
                atlasSource.dec BETWEEN -40 AND -39
            "


